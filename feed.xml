<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://narsil.github.io/narsil.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://narsil.github.io/narsil.github.io/" rel="alternate" type="text/html" /><updated>2020-03-19T03:40:35-05:00</updated><id>https://narsil.github.io/narsil.github.io/feed.xml</id><title type="html">Narsil</title><subtitle>Small experiements insights from ML and software development.</subtitle><entry><title type="html">Super simple estimation of available solar energy</title><link href="https://narsil.github.io/narsil.github.io/energy/2020/03/17/solar-energy.html" rel="alternate" type="text/html" title="Super simple estimation of available solar energy" /><published>2020-03-17T00:00:00-05:00</published><updated>2020-03-17T00:00:00-05:00</updated><id>https://narsil.github.io/narsil.github.io/energy/2020/03/17/solar-energy</id><content type="html" xml:base="https://narsil.github.io/narsil.github.io/energy/2020/03/17/solar-energy.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-17-solar-energy.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Solar-energy&quot;&gt;Solar energy&lt;a class=&quot;anchor-link&quot; href=&quot;#Solar-energy&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;h2 id=&quot;Stefan-boltzmann's-law&quot;&gt;Stefan boltzmann's law&lt;a class=&quot;anchor-link&quot; href=&quot;#Stefan-boltzmann's-law&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;$ \text{Surface energy} = \sigma T^4$&lt;/p&gt;
&lt;p&gt;For the sun, $T = \text{5,778 }K$&lt;/p&gt;
&lt;p&gt;$\sigma = 5.67 \times 10 ^{-8} W.m^{-2}.K^{-4}$&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sympy.physics.units&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;5.67&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5778&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;surface_energy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;surface_energy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;63196526.5460292*watt/meter**2
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Total-emitted-solar-energy&quot;&gt;Total emitted solar energy&lt;a class=&quot;anchor-link&quot; href=&quot;#Total-emitted-solar-energy&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;$ Radiation = \text{Surface of the sun} \times \text{Surface energy} $&lt;/p&gt;
&lt;p&gt;$ Radiation = 4 \pi r^2 \times \text{Surface energy} $&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sympy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;r_sun&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;696_340&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;surface_of_sun&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_sun&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;radiation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;surface_of_sun&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;surface_energy&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;radiation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;1.22573302243694e+26*pi*watt
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Energy-received-at-earth-average-distance&quot;&gt;Energy received at earth average distance&lt;a class=&quot;anchor-link&quot; href=&quot;#Energy-received-at-earth-average-distance&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;$ \text{Radiation received} = \frac{\text{Total sun radiation}}{ \text{sphere at earth's distance}}$&lt;/p&gt;
&lt;p&gt;$ \text{Radiation received} = \frac{Radiation}{ 4 \pi D_{earth-sun}^2} $&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_earth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6_371&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_earth_sun&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;148.88&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;earth_perp_surface&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_earth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sphere&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_earth_sun&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;radiation_received&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;radiation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sphere&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;radiation_received&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;1382.49374484614*watt/meter**2
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Energy-received-by-the-earth-surface-(before-atmosphere)&quot;&gt;Energy received by the earth surface (before atmosphere)&lt;a class=&quot;anchor-link&quot; href=&quot;#Energy-received-by-the-earth-surface-(before-atmosphere)&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;$ \text{Energy received} = \text{radiation received} \times \frac{ \text{visible surface}}{ \text{earth's surface}} $&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;power_received&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;radiation_received&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_earth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;surface_power_received&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;power_received&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_earth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;surface_power_received&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;345.623436211536*watt/meter**2
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;RADIATION-RECEIVED-BY-SYSTEM-EARTH--=-$345-W.m^{-2}$&quot;&gt;RADIATION RECEIVED BY SYSTEM EARTH  = $345 W.m^{-2}$&lt;a class=&quot;anchor-link&quot; href=&quot;#RADIATION-RECEIVED-BY-SYSTEM-EARTH--=-$345-W.m^{-2}$&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Part-2:-How-much-are-we-consumming-right-now&quot;&gt;Part 2: How much are we consumming right now&lt;a class=&quot;anchor-link&quot; href=&quot;#Part-2:-How-much-are-we-consumming-right-now&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;13 511 MTep (&lt;a href=&quot;https://www.iea.org/data-and-statistics?country=WORLD&amp;amp;fuel=Energy%20supply&amp;amp;indicator=Total%20primary%20energy%20supply%20(TPES)%20by%20source&quot;&gt;https://www.iea.org/data-and-statistics?country=WORLD&amp;amp;fuel=Energy%20supply&amp;amp;indicator=Total%20primary%20energy%20supply%20(TPES)%20by%20source&lt;/a&gt;)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sympy.physics.units&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mtep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;41_868&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Humanity_total_annual_consumption&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;13_511&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mtep&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Humanity_total_annual_consumption&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;565678548000000000*joule
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sympy.physics.units&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;humanity_power_consumption&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Humanity_total_annual_consumption&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;365.25&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;humanity_power_consumption&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;17925271503.5364*joule/second
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sympy.physics.units.util&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convert_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;humanity_power_consumption&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;power_received&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;1.01680455844062e-7
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;That's a very small percentage (0.000001% of the theoretical max), of a &quot;dyson sphere&quot; all around the earth. We're not there yet.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;A-bit-more-realistic-approach&quot;&gt;A bit more realistic approach&lt;a class=&quot;anchor-link&quot; href=&quot;#A-bit-more-realistic-approach&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;After the atmosphere only $168 W.m^{-2}$ hit the surface. It's quite complicated to infer it depends on the wavelength of the incoming light, clouds, composition of the atmosphere and so on, so we just take the value from here : &lt;a href=&quot;https://fr.wikipedia.org/wiki/Bilan_radiatif_de_la_Terre&quot;&gt;https://fr.wikipedia.org/wiki/Bilan_radiatif_de_la_Terre&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Then we only have 29% of the earth surface that is landmass (where we can reasonably put solar panels in large quantity)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Of that 31% is covered in forest which are already some natural solar panels we don't  want to remove (for other obvious reasons)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Then solar panels are not 100% efficient. They are roughly only 20% efficient.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;earth_power_received&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;168&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;available_surface&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_earth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.29&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;69&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;max_power&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;earth_power_received&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;available_surface&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_power&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;1.09159507485504e+15*pi*watt
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Running a docker with GPU enabled (for pytorch and tensorflow)</title><link href="https://narsil.github.io/narsil.github.io/ml/docker/2020/03/04/running-gpu-enabled-docker.html" rel="alternate" type="text/html" title="Running a docker with GPU enabled (for pytorch and tensorflow)" /><published>2020-03-04T00:00:00-06:00</published><updated>2020-03-04T00:00:00-06:00</updated><id>https://narsil.github.io/narsil.github.io/ml/docker/2020/03/04/running-gpu-enabled-docker</id><content type="html" xml:base="https://narsil.github.io/narsil.github.io/ml/docker/2020/03/04/running-gpu-enabled-docker.html">&lt;p&gt;Sometimes if you want to contain dependencies you might want to use docker
to containerize your projects. You can also use it for GPU
In order to run docker images with GPU enabled, you are going to need:&lt;/p&gt;

&lt;h1 id=&quot;install-docker&quot;&gt;Install docker&lt;/h1&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get install \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg-agent \
    software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository \
   &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable&quot;
sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.docker.com/install/linux/docker-ce/ubuntu/&quot;&gt;source&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;install-nvidia-container-toolkit&quot;&gt;Install nvidia-container-toolkit&lt;/h1&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Add the package repositories
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/NVIDIA/nvidia-docker&quot;&gt;source&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;launch-the-docker-for-pytorch&quot;&gt;Launch the docker for PyTorch&lt;/h1&gt;

&lt;p&gt;In order to use cuda you need a nvidia enabled image, that will make everything simpler.
You could of course link your own cuda library via volume mounting but it’s cumbersome (and I didn’t check that it works)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Create an account on &lt;a href=&quot;https://ngc.nvidia.com/&quot;&gt;https://ngc.nvidia.com/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Go to the create an API key page &lt;a href=&quot;https://ngc.nvidia.com/setup/api-key&quot;&gt;https://ngc.nvidia.com/setup/api-key&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Generate the key and copy it&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker login nvcr.io
Username: $oauthtoken
Password: &amp;lt;Your Key&amp;gt;
docker run --gpus all -it --rm nvcr.io/nvidia/pytorch:20.02-py3 bash
python -c &quot;import torch; print(torch.cuda.is_available())&quot;
# True
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you fail to login the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker run&lt;/code&gt; command will fail with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unauthenticated&lt;/code&gt; error.&lt;/p&gt;

&lt;p&gt;Caveat: This is the only option for now, docker-compose &lt;em&gt;CANNOT&lt;/em&gt; run the –gpu option.
To check updates for docker compose, look at this &lt;a href=&quot;https://github.com/docker/compose/issues/6691&quot;&gt;issue&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Bonus: Nvidia put up &lt;em&gt;a lot&lt;/em&gt; of containers with various libraries enabled check it out in their &lt;a href=&quot;https://ngc.nvidia.com/catalog/&quot;&gt;catalog&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;enjoy-&quot;&gt;Enjoy !&lt;/h2&gt;</content><author><name>nicolas</name></author><summary type="html">Sometimes if you want to contain dependencies you might want to use docker to containerize your projects. You can also use it for GPU In order to run docker images with GPU enabled, you are going to need:</summary></entry><entry><title type="html">Self KL-divergence for detecting out of distribution data and unsupervised text classification</title><link href="https://narsil.github.io/narsil.github.io/ml/nlp/kldivergence/2020/02/26/self-kl-models.html" rel="alternate" type="text/html" title="Self KL-divergence for detecting out of distribution data and unsupervised text classification" /><published>2020-02-26T00:00:00-06:00</published><updated>2020-02-26T00:00:00-06:00</updated><id>https://narsil.github.io/narsil.github.io/ml/nlp/kldivergence/2020/02/26/self-kl-models</id><content type="html" xml:base="https://narsil.github.io/narsil.github.io/ml/nlp/kldivergence/2020/02/26/self-kl-models.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-02-26-self-kl-models.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;blockquote&gt;&lt;p&gt;TL;DR. By training two models at the same time (same architecture, same loss, but different initialization)
I was able to obtain a consistent out-of-distribution detector by measuring the kl-divergence between model outputs.
This out-of-distribution measure used on text could lead to unsupervised text classification.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;What's-the-problem-?&quot;&gt;What's the problem ?&lt;a class=&quot;anchor-link&quot; href=&quot;#What's-the-problem-?&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;ML models usually are not really capable of predicting how well the data you&lt;br /&gt;
feed them is close to what was in the dataset. It really matters in production 
models as they might make really stupid mistakes just because they are off&lt;br /&gt;
the training set.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's train a simple mnist model (straight out from pytorch tutorial &lt;a href=&quot;https://github.com/pytorch/examples/tree/master/mnist&quot;&gt;https://github.com/pytorch/examples/tree/master/mnist&lt;/a&gt;)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;__future__&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_function&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;argparse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;F&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.optim.lr_scheduler&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StepLR&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9216&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_pool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nll_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_interval&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Train Epoch: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; [&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{:.0f}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;%)]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;Loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{:.6f}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                &lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nll_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# sum up batch loss&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# get the index of the max log-probability&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view_as&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;Test set: Average loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{:.4f}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;, Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{:.0f}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;%)&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Training settings&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argparse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ArgumentParser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;PyTorch MNIST Example&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--batch-size&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input batch size for training (default: 64)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--test-batch-size&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input batch size for testing (default: 1000)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--epochs&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;number of epochs to train (default: 14)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--lr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;LR&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;learning rate (default: 1.0)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--gamma&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;M&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Learning rate step gamma (default: 0.7)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--no-cuda&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;store_true&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;disables CUDA training&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--seed&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;S&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;random seed (default: 1)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--log-interval&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;how many batches to wait before logging training status&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--save-model&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;store_true&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;For Saving the current Model&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse_args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_cuda&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manual_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;cuda&amp;quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;cpu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;num_workers&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;pin_memory&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;../data&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1307&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3081&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expanduser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;../data&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1307&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3081&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adadelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StepLR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;mnist_cnn.pt&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
&lt;span class=&quot;c1&quot;&gt;# mnist()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Then generate an random image for which the model is highly confident yet it's completely absurd. This new image is out of distribution yet the model does not know it. We want to avoid doing such mistakes in production.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.distributions&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.parameter&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mnist_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mnist_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;mnist_cnn.pt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dummy_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adadelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dummy_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dummy_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# print(f&amp;#39;Entropy {entropy.item():.2f}&amp;#39;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;MAX&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;MNIST Model says : This is a {MAX.indices.item()} with probability {MAX.values.item() * 100:.2f}%&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pil_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;240&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;240&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToPILImage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dummy_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pil_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;MNIST Model says : This is a 3 with probability 99.99%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Other-approaches&quot;&gt;Other approaches&lt;a class=&quot;anchor-link&quot; href=&quot;#Other-approaches&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Other out of distribution detector have been proposed. Here is a sample of methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1906.02845.pdf&quot;&gt;Likelihood Ratios for Out-of-Distribution Detection&lt;/a&gt;: Propose to learn 2 distinct models, one &quot;raw&quot;, one with perturbation instilled into the dataset, and look at the log likelihood ratio of the two models, claim is that the difference between the two will reflect how &quot;far&quot; input is from the semantic part of the manifold of X. $p(x) = p(x_{background})p(x_{semantic})$, the perturbation needs to lie only on $x_{semantic}$.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1910.04241.pdf&quot;&gt;Out-of-distribution Detection in Classifiers via Generation&lt;/a&gt;: Propose to use autoencoder (or GANs) to generate a low dimensional representation of the manifold of the dataset X, then perturb X on that representation. Those perturbated examples are trained to become a new &quot;class&quot; of the output of the classifier. &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.02690.pdf&quot;&gt;Enhancing the reliability of Out-of-Distribution Image Detection in Neural Networks (Odin)&lt;/a&gt;: This one uses temperature scaling regarding softmax to generate perturbated input, then look at the probability of the softmax if it passes a threshold. IMO, this paper is interesting as it supposes smoothness properties on In distribution data, and less smooth for out-of-distribution. It does require some examples of out-of-distribution for fitting 3 hyperparameters (temperature, threshold and magnitude of perturbation)&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://openreview.net/pdf?id=Hkxzx0NtDB&quot;&gt;Your classifier is secretly an energy based model and you should treat it like one&lt;/a&gt;: This one adds a new term in the loss to estimate p(x) basically. Multiple ood detectors are proposed, the most efficient being the second derivative of p(x), claiming again that density of p(x) will change more widly in ood space, leading to a good ood detector.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1810.01392.pdf&quot;&gt;WAIC, but Why? Generative Ensembles for Robust Anomaly Detection&lt;/a&gt;: This paper proposes to use an ensemble of models and look at WAIC criterion to detect OOD. It makes many comparison to VAE and GANs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1802.04865v1.pdf&quot;&gt;Learning Confidence for Out-of-Distribution Detection in Neural Networks&lt;/a&gt; : The core idea in this paper is to change the learning loss, to learn confidence as prior task to classification task, a model is allowed to see real label only when it claims it can solve the problem, outputting via another head directly a confidence score. Caveat is that the model might choose to give up and always claim confidence, and another trick is proposed to emphasize the in-distribution vs out-of-distribution by preprocessing inputs to move them towards region of higher confidence. In-distribution tends to move closer to 1 than out-of-distribution. So the direct confidence estimator seems to be &lt;em&gt;smoother&lt;/em&gt; out-of-distribution than in-distribution, where peaks are more likely to be found.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://paperswithcode.com/task/out-of-distribution-detection&quot;&gt;Papers with code&lt;/a&gt;: More links on that hopefully&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Our-approach&quot;&gt;Our approach&lt;a class=&quot;anchor-link&quot; href=&quot;#Our-approach&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;Tl;dr : Make two similar models, with two different random initialization, then train them at the same time.&amp;gt; The ood detector will simply be the a threshold classifier on the KL-divergence between the two outputs.&lt;/strong&gt;
The core argument for this approach is that the neural network captures the dataset manifold (which means it will produce &quot;regular&quot; outputs for in dataset items). For the range of possible values it has random values for a random initialization. If that is true, then we train the model, we shift it's output only on the dataset manifold, and not anywhere else. If that assumption is correct, then the 2 models have very low probability of concurring in their output outside of the manifold if they have been initialized differently.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's quite close to WAIC, &lt;em&gt;but&lt;/em&gt; the two models need to be trained at the same time. The argument is that is should align gradients during the training phase, leading to more correlation for in-dataset prediction for the models. The argument for this supposes that the lottery ticket hypothesis is true, and adds that lottery ticket is unique (or at least that the class of lottery tickets is very thin, and they all highly correlate to each other). If this is true, then the gradients within the network that correspond to this lottery ticket winner in &lt;em&gt;both&lt;/em&gt; networks should be the same (or highly correlated).&lt;/p&gt;
&lt;p&gt;In order to fix the threshold, we found that simply setting it to be 10x the average kl-divergence obtained on the train dataset worked pretty well. As kl divergence is measured in bits, 10x is a quite large margin. More work could be done to study more closely the behaviour of this self kl-divergence.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Experiments&quot;&gt;Experiments&lt;a class=&quot;anchor-link&quot; href=&quot;#Experiments&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Experiment-1&quot;&gt;Experiment 1&lt;a class=&quot;anchor-link&quot; href=&quot;#Experiment-1&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;MNIST attack like failure presented before.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultiNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ModuleList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_multi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nll_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_interval&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Train Epoch: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; [&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{:.0f}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;%)]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;Loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{:.6f}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                &lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_multi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nll_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# get the index of the max log-probability&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view_as&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;Test set: Average loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{:.4f}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;, Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{:.0f}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;%)&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mnist_multi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Training settings&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argparse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ArgumentParser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;PyTorch MNIST Example&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--batch-size&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input batch size for training (default: 64)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--test-batch-size&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input batch size for testing (default: 1000)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--epochs&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;number of epochs to train (default: 14)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--lr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;LR&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;learning rate (default: 1.0)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--gamma&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;M&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Learning rate step gamma (default: 0.7)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--no-cuda&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;store_true&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;disables CUDA training&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--seed&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;S&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;random seed (default: 1)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--log-interval&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;how many batches to wait before logging training status&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--save-model&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;store_true&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;For Saving the current Model&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse_args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_cuda&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manual_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;cuda&amp;quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;cpu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;num_workers&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;pin_memory&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;../data&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1307&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3081&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expanduser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;../data&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1307&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3081&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultiNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adadelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StepLR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_multi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_multi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;mnist_multi_cnn.pt&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        

&lt;span class=&quot;c1&quot;&gt;# mnist_multi()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;kl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;Test set: Average loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{:.4f}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;, len &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;
    
&lt;span class=&quot;n&quot;&gt;multi_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultiNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;multi_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;mnist_multi_cnn.pt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expanduser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;../data&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1307&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3081&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ref_kl_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multi_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cpu&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;
Test set: Average loss: 0.0069, len 10000 

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Now we have 2 models capable of detecting digits, we have instantly 3 checks for checking if the output of our model is valid. The 2 models need to be concording (they need to outputs the same digit as an output), they need to have similar kl-divergence, we actually have a reference for the test set, so we know what kind of divergence we should look for, anything 10x more is definitely ood (we could look at the test set distribution for more fine grain estimation). Because kl divergence is asymetric we have 2 values (it's harder for spiked distribution to have another distribution be close in the kl sense, so taking the max of kl-divergence should be used for out-of-distribution.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.distributions&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.parameter&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;attack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;multi_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultiNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;multi_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;mnist_multi_cnn.pt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dummy_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adadelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dummy_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multi_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dummy_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# print(f&amp;#39;Entropy {entropy.item():.2f}&amp;#39;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;MAX1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;MAX2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;kl_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;batchmean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;kl_loss2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;batchmean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ref_kl_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl_loss2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ref_kl_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;MNIST Model says : This is a {MAX1.indices.item()} with probability {MAX1.values.item() * 100:.2f}%&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;MNIST Model 2 says : This is a {MAX2.indices.item()} with probability {MAX2.values.item() * 100:.2f}%&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;KL-divergence is {kl_loss / ref_kl_loss} {kl_loss2 / ref_kl_loss}&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;ATTACK SUCCEEDED&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;ATTACK FAILED&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pil_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;240&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;240&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToPILImage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dummy_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pil_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt;
        
        
  
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Now if we simply attack the first model like we did earlier, we can see that we can trick it as easily as before. &lt;em&gt;BUT&lt;/em&gt; the second model, does not get attacked which is to be expected.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;attack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;MNIST Model says : This is a 5 with probability 99.32%
MNIST Model 2 says : This is a 1 with probability 51.35%
KL-divergence is 879.1231689453125 221.9772186279297
ATTACK FAILED
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;False&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Even if we try a smarter and attack &lt;strong&gt;both&lt;/strong&gt; models at the same time, we can't succeed at a consistent rate. Be warned, it will succeed sometimes, just not consistently.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;entropy1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;entropy2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;kl_loss1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;batchmean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;kl_loss2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;batchmean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mse_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy2&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl_loss1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl_loss2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;
    
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;MNIST Model says : This is a 7 with probability 11.34%
MNIST Model 2 says : This is a 1 with probability 11.91%
KL-divergence is 0.8557947278022766 0.8770337104797363
ATTACK FAILED
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;False&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Be warned, it will succeed sometimes, just not consistently. For comparison, the first attack succeeds with close to 100% (we couldn't make it fail). Actually because we have 10 classes, and if we supposed out-of-distribution probability distribution is uniformly random, it should be something close to 10%, when our initial random image finds a place where the 2 models intersect on the same digit.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;entropy1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;entropy2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;kl_loss1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;batchmean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;kl_loss2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;batchmean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mse_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy2&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl_loss1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl_loss2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;
    
&lt;span class=&quot;n&quot;&gt;attacks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;F&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;attacks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;success&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Attack success rate {sum(attacks)/len(attacks) * 100:.2f}%&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;.........FF.F...F.FF.F..F....FF...F..FF..F.F.F.FF....F....F.......FF......FF.F.FFF.FF..F............Attack success rate 31.00%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The actual attack range seems to stagnate at around 30% (max observed 41%) with various learning rates and attack steps. There probably are better strategies to attack, this, but the main point is that it became &lt;strong&gt;harder&lt;/strong&gt;. This is expected to be a property of the &lt;em&gt;output landscape&lt;/em&gt;, as the number of classes increases, it should become harder still. Yet as the 30% is larger than the expected 10%, something else might be at play.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Experiment-2&quot;&gt;Experiment 2&lt;a class=&quot;anchor-link&quot; href=&quot;#Experiment-2&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Now let's test this on common ood detection for classic datasets. We will add ood detection for the train dataset, just to check that we don't &lt;em&gt;exclude&lt;/em&gt; too much of the original dataset. Datasets used will be MNIST, FashionMNIST&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Omniglot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FashionMNIST&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FashionMNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dataset_multi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset_cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Training settings&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argparse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ArgumentParser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;PyTorch MNIST Example&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--batch-size&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input batch size for training (default: 64)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--test-batch-size&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input batch size for testing (default: 1000)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--epochs&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;number of epochs to train (default: 14)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--lr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;LR&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;learning rate (default: 1.0)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--gamma&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;M&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Learning rate step gamma (default: 0.7)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--no-cuda&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;store_true&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;disables CUDA training&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--seed&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;S&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;random seed (default: 1)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--log-interval&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metavar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;how many batches to wait before logging training status&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;--save-model&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;store_true&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;For Saving the current Model&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse_args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_cuda&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manual_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;cuda&amp;quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;cpu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;num_workers&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;pin_memory&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dataset_cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;../data&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1307&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3081&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;dataset_cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;../data&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1307&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3081&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
                                    &lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultiNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_scheduler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CyclicLR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;                             
          &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cycle_momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size_up&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;                    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_multi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_multi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run_datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset_cls&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{dataset_cls.__name__}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;.pt&amp;#39;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;dataset_multi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset_cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# run_datasets()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;roc_auc_score&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;cuda&amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;cpu&amp;#39;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset_cls&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{dataset_cls.__name__}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;.pt&amp;#39;&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultiNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;dataset_cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;../data&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1307&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3081&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
             &lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ref_kl_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Ref loss&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ref_kl_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;all_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;all_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset_cls2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;test_loader2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;dataset_cls2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;../data&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1307&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3081&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
             &lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            
            &lt;span class=&quot;n&quot;&gt;OOD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;kl_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;none&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;none&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;kl_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
                &lt;span class=&quot;n&quot;&gt;similar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
                &lt;span class=&quot;n&quot;&gt;normed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ref_kl_loss&lt;/span&gt;
                
                &lt;span class=&quot;n&quot;&gt;kl_anomaly&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;non_concordant&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
                
                &lt;span class=&quot;n&quot;&gt;out_of_distrib&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_anomaly&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;non_concordant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
                &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset_cls2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset_cls&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;all_labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boolean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;all_scores&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
                
                
                &lt;span class=&quot;n&quot;&gt;OOD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_of_distrib&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Trained on &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{dataset_cls.__name__}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; we detected on &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{dataset_cls2.__name__}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{OOD}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/{len(test_loader2.dataset)} ({float(OOD)/len(test_loader2.dataset) * 100:.2f}%) out of distribution&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                   
        &lt;span class=&quot;n&quot;&gt;auc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;roc_auc_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;all_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;AUC for &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{dataset_cls.__name__}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{auc}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test_datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;
Test set: Average loss: 0.0204, len 10000 

Ref loss 0.0204180196672678
Trained on MNIST we detected on MNIST 350/10000 (3.50%) out of distribution
Trained on MNIST we detected on FashionMNIST 7334/10000 (73.34%) out of distribution
AUC for MNIST : 0.9692911949999999

Test set: Average loss: 0.0490, len 10000 

Ref loss 0.0490430459022522
Trained on FashionMNIST we detected on MNIST 6141/10000 (61.41%) out of distribution
Trained on FashionMNIST we detected on FashionMNIST 1040/10000 (10.40%) out of distribution
AUC for FashionMNIST : 0.8571711399999999
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;So we can see that we achieve, with no tuning whatsoever a decent out of distribution detector. We seem to achieve much better AUROC on MNIST, probably because the in-distribution learning seems to be much better (99% test accuracy vs 92% for fastionMNIST). So to False positives for fashionMNIST probably come from this hard to learn in-distribution. Some fine tuning needs to be done to get better results. We also have to keep in mind, that the models to learn this are quite small (2M parameters but only 2 convolution layers) so the lottery hypothesis validity for such a network might be questionned.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Experiment-2-bis&quot;&gt;Experiment 2 bis&lt;a class=&quot;anchor-link&quot; href=&quot;#Experiment-2-bis&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Same experiment but with fine tuned, larger networks on the same datasets&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Experiment-3&quot;&gt;Experiment 3&lt;a class=&quot;anchor-link&quot; href=&quot;#Experiment-3&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Check that two identical networks (same initalization) actually don't work. It's just a sanity check. We should obtain always kl_div = 0 no matter where we are in the input space.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Experiment-4&quot;&gt;Experiment 4&lt;a class=&quot;anchor-link&quot; href=&quot;#Experiment-4&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Test on a larger output space, like CIFAR-100 and SVHN, to check that part of the limits are actually due to small number of output classes
for MNIST/FashionMNIST
Other idea is to test on Transformers. Early experiment seems to show that we can use that idea to detect different language within text with just the kl_div used as a distance.&lt;/p&gt;
&lt;p&gt;Found French book within english books dataset, AND english paragraphs &lt;em&gt;within&lt;/em&gt; this french book.
Needs some work to clean this experiment&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Experiment-5&quot;&gt;Experiment 5&lt;a class=&quot;anchor-link&quot; href=&quot;#Experiment-5&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Need to test with various training schemes, regularization schemes (dropout, batchnorm, l2 penalization) and so on. We should find that the smoother in-distribution our models behave the more this method should work. Hopefully test accuracy &lt;em&gt;should&lt;/em&gt; be a good smoothness proxy.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Experiment-6--(Unsupervised-text-classification)-or-fuse-with-experiment-4?&quot;&gt;Experiment 6  (Unsupervised text classification) or fuse with experiment 4?&lt;a class=&quot;anchor-link&quot; href=&quot;#Experiment-6--(Unsupervised-text-classification)-or-fuse-with-experiment-4?&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;ul&gt;
&lt;li&gt;Show that small network trained on a single english book enables to detect different languages
or different patterns of writing (old english, irish, french, or event dictionnaries)&lt;/li&gt;
&lt;li&gt;The detection is super fined grained capable of detecting english within a French book.&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Experiment-7&quot;&gt;Experiment 7&lt;a class=&quot;anchor-link&quot; href=&quot;#Experiment-7&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Run this method with 2, 3, 4, and so on models. We should get exponential improved accuracy, if the random behavious for out-of-distribution for models is correct.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Limits&quot;&gt;Limits&lt;a class=&quot;anchor-link&quot; href=&quot;#Limits&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The pros for this method are that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It's super simple to implement, and only costs a constant factor in training time.&lt;/li&gt;
&lt;li&gt;You could also extend this to 3, 4 side models, and it &lt;em&gt;should&lt;/em&gt; improve robustness exponentially if the random factors are correct. If we keep this number small, it will still be constant cost factor.&lt;/li&gt;
&lt;li&gt;It does &lt;em&gt;not&lt;/em&gt; require a perturbation model for input data, which in itself is subject to fine-tuning.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The cons is that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It does not work so well on low dimensional output spaces. &lt;/li&gt;
&lt;li&gt;It seems other methods have better results than this one.&lt;/li&gt;
&lt;li&gt;It only works for models that output probability distributions (hard to extend to object detection, generation and other tasks)&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Future-Work&quot;&gt;Future Work&lt;a class=&quot;anchor-link&quot; href=&quot;#Future-Work&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;There is a lot more experiments necessary to verify that the hypothesis in favor of that approach hold. Try to find ways to implement that in other tasks. How to improve out-of-distribution detection.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Model based encodings (3)</title><link href="https://narsil.github.io/narsil.github.io/ml/nlp/2019/08/06/model-based-bpe-encodings-3.html" rel="alternate" type="text/html" title="Model based encodings (3)" /><published>2019-08-06T00:00:00-05:00</published><updated>2019-08-06T00:00:00-05:00</updated><id>https://narsil.github.io/narsil.github.io/ml/nlp/2019/08/06/model-based-bpe-encodings-3</id><content type="html" xml:base="https://narsil.github.io/narsil.github.io/ml/nlp/2019/08/06/model-based-bpe-encodings-3.html">&lt;p&gt;In the &lt;a href=&quot;/narsil.github.io/ml/nlp/2019/05/16/model-based-bpe-encodings.html&quot;&gt;first segment&lt;/a&gt;
we looked into how we could make a BPE
based encoding, not only based on frequency in the dataset, but directly on the
model probability measure of the next token. In that article I mention that
dynamic BPE are costly because they stop being a one time operation but have to
be done for every batch because the vocabulary might have changed. In this
article I try to completely remove the “static” BPE approach and replace it
completely with ML blocks.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h1 id=&quot;tldr-in-this-article-we-present-an-idea-to-replace-classical-bpe-algorithm-with-a-pure-ml-version-of-it&quot;&gt;TL;DR In this article we present an idea to replace classical BPE algorithm with a pure ML version of it.&lt;/h1&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;what-is-the-goal-&quot;&gt;What is the goal ?&lt;/h2&gt;

&lt;p&gt;So the goal is to replace BPE algorithm. So it’s go from something like&lt;/p&gt;

&lt;p&gt;“T|h|e| |c|a|t| |a|t|e| |t|h|e| |a|p|p|l|e|.”&lt;/p&gt;

&lt;p&gt;To something that has less elements :&lt;/p&gt;

&lt;p&gt;“The |ca|t |at|e |the| |app|le|.”&lt;/p&gt;

&lt;p&gt;In one sentence, BPE fuses bytes to form tokens based on frequency in the full
dataset. For a more detailed example, look that &lt;a href=&quot;/narsil.github.io/ml/nlp/2019/05/16/model-based-bpe-encodings.html&quot;&gt;the previous
article&lt;/a&gt;.
In this example, you can see there is always a split after a space. That’s a
limitation of BPE so actually our target might look different, maybe more like&lt;/p&gt;

&lt;p&gt;“The cat |at|e |the app|le|.”&lt;/p&gt;

&lt;p&gt;Here we can notice that “The cat” is a full token and contain 2 actual words.
So the goal is to fuse some starting bytes into N tokens (let’s say ~10k) that
hopefully capture regularities in our dataset and are at least correlated to
frequency in the original dataset like BPE was.&lt;/p&gt;

&lt;p&gt;Another property we need to have from BPE is that it can encode an arbitrary
string of text. It does not matter if it’s not the same language or even if it
makes sense, you CAN encode it, that is a very desirable property. It avoids
the &lt;a href=&quot;https://medium.com/cisco-emerge/creating-semantic-representations-of-out-of-vocabulary-words-for-common-nlp-tasks-842dbdafba18&quot;&gt;out-of-vocabulary&lt;/a&gt; problem.&lt;/p&gt;

&lt;h2 id=&quot;approach&quot;&gt;Approach&lt;/h2&gt;

&lt;h3 id=&quot;tokenization&quot;&gt;Tokenization&lt;/h3&gt;

&lt;p&gt;So let’s imagine we have a trained transformer like
&lt;a href=&quot;https://openai.com/blog/better-language-models/&quot;&gt;GPT-2&lt;/a&gt;. But trained on bytes
directly NOT on tokens like the original transformer. Now we can use the idea
that when a model is highly confident, it probably means that what it’s about
to predict is “in the same token”. Let’s take an example. Try to predict the
following Character (as in a single letter) in the next 2 sentences&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sentence 1: “Who are yo…”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sentence 2 : “I like …”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the first sentence, normally you would vote with very high confidence for
“u”, whereas in the second sentence, you lack a lot of context to be exactly
sure on what’s coming next. So “you” would be a token, whereas “like …” can’t
be a single token, it has to be at least 2, “like “ and “…”.&lt;/p&gt;

&lt;p&gt;Here is a small gif of actual probabilities of the language model on a small sentence&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/narsil.github.io/images/models-2-approach.gif&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can see the in the left of the graph the probabilities drop, those are the
tokens that try to get predicted but are missing context (because we have very
few characters before them. For the right side, you can see the drops in probability
are pretty consistent and correspond to word boundaries most often.&lt;/p&gt;

&lt;h3 id=&quot;handling-unknown-tokens&quot;&gt;Handling unknown tokens&lt;/h3&gt;

&lt;p&gt;Now we know how we are going to “fuse” characters, but we are not done yet. BPE
tokens are a discrete SET of identified values from 0 to N (~10k in this
experiment). Also BPE can encode an arbitrary new string by using it’s fusion
table. So we can’t just run our algorithm on some specific dataset, count all
the tokens created and declare that these are the N tokens for eternity. Let’s
imagine I feed my algorithm a new sentence, in a different language, French for
instance.&lt;/p&gt;

&lt;p&gt;“J’adore l’Italie.”&lt;/p&gt;

&lt;p&gt;We can run our “tokenizer” on this, and receive something like this&lt;/p&gt;

&lt;p&gt;“J|’|ado|re |l’|Ita|lie.”&lt;/p&gt;

&lt;p&gt;Now “ado” might not be in our original list, so what do we do with it ? Do we
declare the token wrong and split it ? That would be odd.&lt;/p&gt;

&lt;p&gt;A key insight, is to remember that the first step of the discrete “token” once
it enters the model (all of them do that, it’s really not specific to
transformer or GPT-2) it gets embedded, meaning we go from a number between 1
and N, to a vector in &lt;em&gt;d&lt;/em&gt; dimension space (&lt;em&gt;d&lt;/em&gt; is between 100 and 1000 generally).&lt;/p&gt;

&lt;p&gt;For instance token 3 gets mapped to [0.3, -0.15, 1.4, …] while token 4 gets mapped
to [-2.4, -0.014, 0.45, …]&lt;/p&gt;

&lt;p&gt;So the idea it to generate directly a token embedding (a vector in &lt;em&gt;d&lt;/em&gt;-dimension), not necessarily a
discrete value (a number between 0 and vocabulary size).&lt;/p&gt;

&lt;p&gt;In order to do that we need that all tokens should now be represented in the
same way by a &lt;em&gt;d&lt;/em&gt; dimension space vector. One way to achieve that is to use an
autoencoder.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png&quot; alt=&quot;&quot; /&gt;
or with code&lt;/p&gt;

&lt;p&gt;The core idea is that when we encounter a new unseen token like “ado” it will still have
a representation through the VAE, and will probably be close to a known token like “add”.
This can help the network overcome odd tokenization or spelling errors.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;## The name is VAE but I didn't use the internal KL loss in the end as it prevented/slowed down the learning.
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;VAE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VAE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CONTEXT_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc21&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc22&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# x is [Batch, Context size, Embedding dim]
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reparameterize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CONTEXT_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reparameterize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;final-network&quot;&gt;Final network&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/narsil.github.io/images/model-based-2.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;Here is a summary of the values of the tokenization we got.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Raw&lt;/th&gt;
      &lt;th&gt;BPE&lt;/th&gt;
      &lt;th&gt;Model based&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Vocabulary size&lt;/td&gt;
      &lt;td&gt;256&lt;/td&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;26262&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;#Tokens&lt;/td&gt;
      &lt;td&gt;387k&lt;/td&gt;
      &lt;td&gt;90k&lt;/td&gt;
      &lt;td&gt;92k&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Avg token length&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3.3&lt;/td&gt;
      &lt;td&gt;6.65&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here is a excerpt of the kind of tokenization we created&lt;/p&gt;

&lt;pre&gt;&lt;i&gt;|He w|as on|e of|
the |most |n|oticea|ble member|s of the| Reform| Club|, |th|ough| he| s|eemed
|always |to |avoid |att|racting at|tention|; an en|ig|mat|i|cal |p|erson|age|,|
|ab|out whom l|ittle| was |known|, |e|xc|ept that |he| w|as |a |poli|shed m|an|
o|f |th|e |wo|rld|.  |Pe|ople sa|id| that h|e |re|sembl|ed| |Byron|--at least|
t|hat |his hea|d w|as |Byronic|; |but| he was |a |b|earde|d, tranquil| Byron|,
who| |might live| on a |thousand year|s |w|ithout g|r|owing o|ld|.|

|Certainly| an| English|man|, it |was |m|ore |doubt|ful w|h|ether |Phileas Fogg|
w|as |a |London|er|.&lt;/i&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;/txt/80day_tokenized_exp2.txt&quot;&gt;Full text&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This version has been done with epsilon=0.0015.&lt;/p&gt;

&lt;p&gt;As you can see, “Phileas Fogg” is already a token in this situation, which is a multi-word token not
achievable by regular BPE. You can also see, a lot of words contain only single bytes tokens which
is why this method compresses LESS than regular BPE at the same vocabulary size.
Another note is that classical words like “was” is already a token (in the last sentence) but it’s not always
the case, this token is context dependent now !&lt;/p&gt;

&lt;h2 id=&quot;vae&quot;&gt;VAE&lt;/h2&gt;

&lt;p&gt;After the VAE step, the reconstruction is not perfect yet perfectly legible.&lt;/p&gt;

&lt;pre&gt;&lt;i&gt;|He w|as on|e of|
the |most |n|oticea|ihe member|s of the| reform| Club|, |th|ough| he| s|eemed
|always |to |asoid |att|nacting at|tention|, an en|ig|mat|i|cal |p|erson|age|,|
|ab|
it whom l|ittle| was | nown|, |e|xc| pt that |he| w|as |a |poli|shed m|an|
o|f |th|e |wo|rld|.  |Pe|ople sa|id| that h|e |re|sembl|ed| |pyron| cat least|
t|hat |has hea|d w|as |blronic|; |but| he was |a |b|earde|in tranquil| pyron|
who| |eight live| on a |dar  and year|s |w|ithout g|r|owing o|ld|.|

|rertainly| an| English|man|, it |was |m|ore |doubt|ful w|h|ether |Phileas Fogg|
w|as |a |London|er|.&lt;/i&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;/txt/80day_reconstructed2.txt&quot;&gt;Full text&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Most of the errors tend to lie in the first characters of &lt;em&gt;long tokens&lt;/em&gt;.That’s because, I’m forced to padd
the input of the VAE and to mask that padding. In practice that means that the first characters of long tokens get updated
less that the others so necessarily they contain more errors. &lt;a href=&quot;#notes&quot;&gt;More information&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;upper-level&quot;&gt;Upper level&lt;/h2&gt;

&lt;p&gt;In order to complete the experiment, we need to check that the original language model
done directly at BPE level can be done with this new model-based BPE encoding.&lt;/p&gt;

&lt;p&gt;It’s pretty slow to train that upper level because we need to flow the
gradients all the way through the VAE decoder, and the lower layer decoding
step, in order to get the &lt;strong&gt;character level loss&lt;/strong&gt; (softmax + nll_loss) to properly train something.
That’s a limit of the current approach.&lt;/p&gt;

&lt;p&gt;If we randomly split the text into train&amp;amp;validation, we can learn almost perfectly (97% top-1 character level accuracy)
the language model on top of that Model based BPE.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/narsil.github.io/images/models-2-overfit.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However this can be considered &lt;strong&gt;overfitting&lt;/strong&gt; because even though a specific input
was never seen in the valid set, a very close one &lt;em&gt;was&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;If instead we try to compare with a fixed split, where the last part of the book
is considered the valid set, then we get much lower result.&lt;/p&gt;

&lt;p&gt;We could achieve 25% exact character matching, and ~77%
top-10 character matching on the valid set, which is the end of the book !
The same results happen with BPE, even worse ! we can’t get past 13% top-1 and 25% top-10
on the regular BPE. That’s understandable because the dataset is very small and
the last part of the book is different so it’s very hard to infer it from just the
beginning and no other text.&lt;/p&gt;

&lt;p&gt;Another note, is that model based BPE are not tokenizing deterministicly, there
is some variance to it, depending on the context of a particular word.
This actually seems to be a good property (See &lt;a href=&quot;https://arxiv.org/abs/1804.10959&quot;&gt;this&lt;/a&gt;) and
might explain away the better performance of model based BPE over regular BPE.
Keep in mind it’s 25% of the &lt;strong&gt;characters&lt;/strong&gt; that are correct.
If we looked at a discrete view of &lt;strong&gt;tokens&lt;/strong&gt; we probably would have a much higher prediction rate (it’s left for future work for now).&lt;/p&gt;

&lt;p&gt;Here is a picture from the tensorboard values, P_1 is probability that the
character predicted is the correct one, P_10 is that it is in the top-10
values.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/narsil.github.io/images/models-2-upper.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The overfitting starts happening around the ~1M steps mark.&lt;/p&gt;

&lt;h3 id=&quot;notes&quot;&gt;Notes&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;In the experiment we learned model by model, freezing the lower model
before training something on top. It’s because the batching of different
layers occur differently. Learning the whole thing end-to-end is probably going
to need some thought. The batching is easy for the lower level, every batch
needs a tensor of shape CONTEXT_SIZE (=64) of [0-255] ints. For the VAE, we
need to have a variable length (depending on the length token) times EMBEDDING_DIM
(=128). The upper level needs only tensors of size CONTEXT_SIZE *
EMBEDDING_DIM yet if we want to try and end-to-end training, we have &lt;strong&gt;no
idea&lt;/strong&gt; how many bytes we need to generate 1 correct tensor in the upper layer.
We know it’s no more than CONTEXT_SIZE² but that would be prohibitive to use
that value.&lt;/li&gt;
  &lt;li&gt;The loss NEEDS to always be the byte-level nll loss. At first I thought a
simple MSE loss in the embedding space could be enough to learn the proper
models. It seems to not be the case. I could only achieve meaningful results by
always referring to the original strings and calculating the NLL Loss. When
using this loss, the MSE actually &lt;em&gt;increases&lt;/em&gt;. This leads me to think that
encoding/decoding + softmax are highly anisotropic operators. Looking at the
singular values of the embedding matrix, we can see that the highest one is
7.35, the lowest one 0.12, so there are 2 orders of magnitude between the 2.
This anisotropy means that the MSE loss which considers all dimensions of the
embeddding equal is actually couting way too much some irrelevant dimensions.
It would be much faster and simpler if we could train directly on MSE (it would
enable us to train without running all the decoding steps to generate the
loss). So we need to add some spectral loss on the embedding on the lower
language model to test that hypothesis.&lt;/li&gt;
  &lt;li&gt;The tokens have variable lengths. In order to fix this, we have to padd all
sequences during learning. Because we padd, we have to mask the padding
during training for both VAE and upper LM. Keeping track of this is pretty
nifty and it means gradients on rarely used places will rarely get updated. So
we will almost surely miss some letters in our tokens. Either at the front or
the end of the token depending on how we padd the tokens.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;future-work&quot;&gt;&lt;strong&gt;Future work&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Actually testing discretizing the tokens to compare with the regular BPE. In that direction,
also comparing with a randomized tokenizer as used in &lt;a href=&quot;https://github.com/google/sentencepiece&quot;&gt;SentencePiece&lt;/a&gt;
to make sure the results are actually comparable and are indeed linked to tokenization variance.&lt;/li&gt;
  &lt;li&gt;The masking problem really seems to be a current limit of the model. Finding a workaround would be really valuable.&lt;/li&gt;
  &lt;li&gt;The fact that the NLL loss is required slows down upper layers. It would be awesome if we could smooth out
the encoding/decoding matrix so that L2 directly for VAE and the upper layer works. It probably goes against regular
language model embedding so not sure it’s doable.&lt;/li&gt;
  &lt;li&gt;Making the epsilon based tokenization directly after the embedding layer. This would help &lt;em&gt;stack&lt;/em&gt; those levels hopefully learning
higher and higer representations of text leading the sentence embedding and so on.&lt;/li&gt;
  &lt;li&gt;On the same idea, another direction would be to do actual discrete tokenization to allow for the models to stack.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>nicolas</name></author><summary type="html">In the first segment we looked into how we could make a BPE based encoding, not only based on frequency in the dataset, but directly on the model probability measure of the next token. In that article I mention that dynamic BPE are costly because they stop being a one time operation but have to be done for every batch because the vocabulary might have changed. In this article I try to completely remove the “static” BPE approach and replace it completely with ML blocks.</summary></entry><entry><title type="html">Model based encodings (2)</title><link href="https://narsil.github.io/narsil.github.io/ml/nlp/2019/06/06/model-based-bpe-encodings-2.html" rel="alternate" type="text/html" title="Model based encodings (2)" /><published>2019-06-06T00:00:00-05:00</published><updated>2019-06-06T00:00:00-05:00</updated><id>https://narsil.github.io/narsil.github.io/ml/nlp/2019/06/06/model-based-bpe-encodings-2</id><content type="html" xml:base="https://narsil.github.io/narsil.github.io/ml/nlp/2019/06/06/model-based-bpe-encodings-2.html">&lt;p&gt;In the &lt;a href=&quot;/narsil.github.io/ml/nlp/2019/05/16/model-based-bpe-encodings.html&quot;&gt;first segment&lt;/a&gt;
we looked into how we could make a BPE
based encoding, not only based on frequency in the dataset, but directly on the
model probability measure of the next token. In that article I mention that
dynamic BPE are costly because they stop being a one time operation but have to
be done for every batch because the vocabulary might have changed. In this
article I try to completely remove the “static” BPE approach and replace it
completely with ML blocks.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h1 id=&quot;tldr-in-this-article-we-present-an-idea-to-replace-classical-bpe-algorithm-with-a-pure-ml-version-of-it&quot;&gt;TL;DR In this article we present an idea to replace classical BPE algorithm with a pure ML version of it.&lt;/h1&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;what-is-the-goal-&quot;&gt;What is the goal ?&lt;/h2&gt;

&lt;p&gt;So the goal is to replace BPE algorithm. So it’s go from something like&lt;/p&gt;

&lt;p&gt;“T|h|e| |c|a|t| |a|t|e| |t|h|e| |a|p|p|l|e|.”&lt;/p&gt;

&lt;p&gt;To something that has less elements :&lt;/p&gt;

&lt;p&gt;“The |ca|t |at|e |the| |app|le|.”&lt;/p&gt;

&lt;p&gt;In one sentence, BPE fuses bytes to form tokens based on frequency in the full
dataset. For a more detailed example, look that &lt;a href=&quot;/narsil.github.io/ml/nlp/2019/05/16/model-based-bpe-encodings.html&quot;&gt;the previous
article&lt;/a&gt;.
In this example, you can see there is always a split after a space. That’s a
limitation of BPE so actually our target might look different, maybe more like&lt;/p&gt;

&lt;p&gt;“The cat |at|e |the app|le|.”&lt;/p&gt;

&lt;p&gt;Here we can notice that “The cat” is a full token and contain 2 actual words.
So the goal is to fuse some starting bytes into N tokens (let’s say ~10k) that
hopefully capture regularities in our dataset and are at least correlated to
frequency in the original dataset like BPE was.&lt;/p&gt;

&lt;p&gt;Another property we need to have from BPE is that it can encode an arbitrary
string of text. It does not matter if it’s not the same language or even if it
makes sense, you CAN encode it, that is a very desirable property. It avoids
the &lt;a href=&quot;https://medium.com/cisco-emerge/creating-semantic-representations-of-out-of-vocabulary-words-for-common-nlp-tasks-842dbdafba18&quot;&gt;out-of-vocabulary&lt;/a&gt; problem.&lt;/p&gt;

&lt;h2 id=&quot;approach&quot;&gt;Approach&lt;/h2&gt;

&lt;h3 id=&quot;tokenization&quot;&gt;Tokenization&lt;/h3&gt;

&lt;p&gt;So let’s imagine we have a trained transformer like
&lt;a href=&quot;https://openai.com/blog/better-language-models/&quot;&gt;GPT-2&lt;/a&gt;. But trained on bytes
directly NOT on tokens like the original transformer. Now we can use the idea
that when a model is highly confident, it probably means that what it’s about
to predict is “in the same token”. Let’s take an example. Try to predict the
following Character (as in a single letter) in the next 2 sentences&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sentence 1: “Who are yo…”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sentence 2 : “I like …”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the first sentence, normally you would vote with very high confidence for
“u”, whereas in the second sentence, you lack a lot of context to be exactly
sure on what’s coming next. So “you” would be a token, whereas “like …” can’t
be a single token, it has to be at least 2, “like “ and “…”.&lt;/p&gt;

&lt;p&gt;Here is a small gif of actual probabilities of the language model on a small sentence&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/narsil.github.io/images/models-2-approach.gif&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can see the in the left of the graph the probabilities drop, those are the
tokens that try to get predicted but are missing context (because we have very
few characters before them. For the right side, you can see the drops in probability
are pretty consistent and correspond to word boundaries most often.&lt;/p&gt;

&lt;h3 id=&quot;handling-unknown-tokens&quot;&gt;Handling unknown tokens&lt;/h3&gt;

&lt;p&gt;Now we know how we are going to “fuse” characters, but we are not done yet. BPE
tokens are a discrete SET of identified values from 0 to N (~10k in this
experiment). Also BPE can encode an arbitrary new string by using it’s fusion
table. So we can’t just run our algorithm on some specific dataset, count all
the tokens created and declare that these are the N tokens for eternity. Let’s
imagine I feed my algorithm a new sentence, in a different language, French for
instance.&lt;/p&gt;

&lt;p&gt;“J’adore l’Italie.”&lt;/p&gt;

&lt;p&gt;We can run our “tokenizer” on this, and receive something like this&lt;/p&gt;

&lt;p&gt;“J|’|ado|re |l’|Ita|lie.”&lt;/p&gt;

&lt;p&gt;Now “ado” might not be in our original list, so what do we do with it ? Do we
declare the token wrong and split it ? That would be odd.&lt;/p&gt;

&lt;p&gt;A key insight, is to remember that the first step of the discrete “token” once
it enters the model (all of them do that, it’s really not specific to
transformer or GPT-2) it gets embedded, meaning we go from a number between 1
and N, to a vector in &lt;em&gt;d&lt;/em&gt; dimension space (&lt;em&gt;d&lt;/em&gt; is between 100 and 1000 generally).&lt;/p&gt;

&lt;p&gt;For instance token 3 gets mapped to [0.3, -0.15, 1.4, …] while token 4 gets mapped
to [-2.4, -0.014, 0.45, …]&lt;/p&gt;

&lt;p&gt;So the idea it to generate directly a token embedding (a vector in &lt;em&gt;d&lt;/em&gt;-dimension), not necessarily a
discrete value (a number between 0 and vocabulary size).&lt;/p&gt;

&lt;p&gt;In order to do that we need that all tokens should now be represented in the
same way by a &lt;em&gt;d&lt;/em&gt; dimension space vector. One way to achieve that is to use an
autoencoder.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png&quot; alt=&quot;&quot; /&gt;
or with code&lt;/p&gt;

&lt;p&gt;The core idea is that when we encounter a new unseen token like “ado” it will still have
a representation through the VAE, and will probably be close to a known token like “add”.
This can help the network overcome odd tokenization or spelling errors.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;## The name is VAE but I didn't use the internal KL loss in the end as it prevented/slowed down the learning.
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;VAE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VAE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CONTEXT_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc21&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc22&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# x is [Batch, Context size, Embedding dim]
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reparameterize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CONTEXT_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reparameterize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;final-network&quot;&gt;Final network&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/narsil.github.io/images/model-based-2.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;Here is a summary of the values of the tokenization we got.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Raw&lt;/th&gt;
      &lt;th&gt;BPE&lt;/th&gt;
      &lt;th&gt;Model based&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Vocabulary size&lt;/td&gt;
      &lt;td&gt;256&lt;/td&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;26262&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;#Tokens&lt;/td&gt;
      &lt;td&gt;387k&lt;/td&gt;
      &lt;td&gt;90k&lt;/td&gt;
      &lt;td&gt;92k&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Avg token length&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3.3&lt;/td&gt;
      &lt;td&gt;6.65&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here is a excerpt of the kind of tokenization we created&lt;/p&gt;

&lt;pre&gt;&lt;i&gt;|He w|as on|e of|
the |most |n|oticea|ble member|s of the| Reform| Club|, |th|ough| he| s|eemed
|always |to |avoid |att|racting at|tention|; an en|ig|mat|i|cal |p|erson|age|,|
|ab|out whom l|ittle| was |known|, |e|xc|ept that |he| w|as |a |poli|shed m|an|
o|f |th|e |wo|rld|.  |Pe|ople sa|id| that h|e |re|sembl|ed| |Byron|--at least|
t|hat |his hea|d w|as |Byronic|; |but| he was |a |b|earde|d, tranquil| Byron|,
who| |might live| on a |thousand year|s |w|ithout g|r|owing o|ld|.|

|Certainly| an| English|man|, it |was |m|ore |doubt|ful w|h|ether |Phileas Fogg|
w|as |a |London|er|.&lt;/i&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;/txt/80day_tokenized_exp2.txt&quot;&gt;Full text&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This version has been done with epsilon=0.0015.&lt;/p&gt;

&lt;p&gt;As you can see, “Phileas Fogg” is already a token in this situation, which is a multi-word token not
achievable by regular BPE. You can also see, a lot of words contain only single bytes tokens which
is why this method compresses LESS than regular BPE at the same vocabulary size.
Another note is that classical words like “was” is already a token (in the last sentence) but it’s not always
the case, this token is context dependent now !&lt;/p&gt;

&lt;h2 id=&quot;vae&quot;&gt;VAE&lt;/h2&gt;

&lt;p&gt;After the VAE step, the reconstruction is not perfect yet perfectly legible.&lt;/p&gt;

&lt;pre&gt;&lt;i&gt;|He w|as on|e of|
the |most |n|oticea|ihe member|s of the| reform| Club|, |th|ough| he| s|eemed
|always |to |asoid |att|nacting at|tention|, an en|ig|mat|i|cal |p|erson|age|,|
|ab|
it whom l|ittle| was | nown|, |e|xc| pt that |he| w|as |a |poli|shed m|an|
o|f |th|e |wo|rld|.  |Pe|ople sa|id| that h|e |re|sembl|ed| |pyron| cat least|
t|hat |has hea|d w|as |blronic|; |but| he was |a |b|earde|in tranquil| pyron|
who| |eight live| on a |dar  and year|s |w|ithout g|r|owing o|ld|.|

|rertainly| an| English|man|, it |was |m|ore |doubt|ful w|h|ether |Phileas Fogg|
w|as |a |London|er|.&lt;/i&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;/txt/80day_reconstructed2.txt&quot;&gt;Full text&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Most of the errors tend to lie in the first characters of &lt;em&gt;long tokens&lt;/em&gt;.That’s because, I’m forced to padd
the input of the VAE and to mask that padding. In practice that means that the first characters of long tokens get updated
less that the others so necessarily they contain more errors. &lt;a href=&quot;#notes&quot;&gt;More information&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;upper-level&quot;&gt;Upper level&lt;/h2&gt;

&lt;p&gt;In order to complete the experiment, we need to check that the original language model
done directly at BPE level can be done with this new model-based BPE encoding.&lt;/p&gt;

&lt;p&gt;It’s pretty slow to train that upper level because we need to flow the
gradients all the way through the VAE decoder, and the lower layer decoding
step, in order to get the &lt;strong&gt;character level loss&lt;/strong&gt; (softmax + nll_loss) to properly train something.
That’s a limit of the current approach.&lt;/p&gt;

&lt;p&gt;If we randomly split the text into train&amp;amp;validation, we can learn almost perfectly (97% top-1 character level accuracy)
the language model on top of that Model based BPE.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/narsil.github.io/images/models-2-overfit.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However this can be considered &lt;strong&gt;overfitting&lt;/strong&gt; because even though a specific input
was never seen in the valid set, a very close one &lt;em&gt;was&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;If instead we try to compare with a fixed split, where the last part of the book
is considered the valid set, then we get much lower result.&lt;/p&gt;

&lt;p&gt;We could achieve 25% exact character matching, and ~77%
top-10 character matching on the valid set, which is the end of the book !
The same results happen with BPE, even worse ! we can’t get past 13% top-1 and 25% top-10
on the regular BPE. That’s understandable because the dataset is very small and
the last part of the book is different so it’s very hard to infer it from just the
beginning and no other text.&lt;/p&gt;

&lt;p&gt;Another note, is that model based BPE are not tokenizing deterministicly, there
is some variance to it, depending on the context of a particular word.
This actually seems to be a good property (See &lt;a href=&quot;https://arxiv.org/abs/1804.10959&quot;&gt;this&lt;/a&gt;) and
might explain away the better performance of model based BPE over regular BPE.
Keep in mind it’s 25% of the &lt;strong&gt;characters&lt;/strong&gt; that are correct.
If we looked at a discrete view of &lt;strong&gt;tokens&lt;/strong&gt; we probably would have a much higher prediction rate (it’s left for future work for now).&lt;/p&gt;

&lt;p&gt;Here is a picture from the tensorboard values, P_1 is probability that the
character predicted is the correct one, P_10 is that it is in the top-10
values.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/narsil.github.io/images/models-2-upper.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The overfitting starts happening around the ~1M steps mark.&lt;/p&gt;

&lt;h3 id=&quot;notes&quot;&gt;Notes&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;In the experiment we learned model by model, freezing the lower model
before training something on top. It’s because the batching of different
layers occur differently. Learning the whole thing end-to-end is probably going
to need some thought. The batching is easy for the lower level, every batch
needs a tensor of shape CONTEXT_SIZE (=64) of [0-255] ints. For the VAE, we
need to have a variable length (depending on the length token) times EMBEDDING_DIM
(=128). The upper level needs only tensors of size CONTEXT_SIZE *
EMBEDDING_DIM yet if we want to try and end-to-end training, we have &lt;strong&gt;no
idea&lt;/strong&gt; how many bytes we need to generate 1 correct tensor in the upper layer.
We know it’s no more than CONTEXT_SIZE² but that would be prohibitive to use
that value.&lt;/li&gt;
  &lt;li&gt;The loss NEEDS to always be the byte-level nll loss. At first I thought a
simple MSE loss in the embedding space could be enough to learn the proper
models. It seems to not be the case. I could only achieve meaningful results by
always referring to the original strings and calculating the NLL Loss. When
using this loss, the MSE actually &lt;em&gt;increases&lt;/em&gt;. This leads me to think that
encoding/decoding + softmax are highly anisotropic operators. Looking at the
singular values of the embedding matrix, we can see that the highest one is
7.35, the lowest one 0.12, so there are 2 orders of magnitude between the 2.
This anisotropy means that the MSE loss which considers all dimensions of the
embeddding equal is actually couting way too much some irrelevant dimensions.
It would be much faster and simpler if we could train directly on MSE (it would
enable us to train without running all the decoding steps to generate the
loss). So we need to add some spectral loss on the embedding on the lower
language model to test that hypothesis.&lt;/li&gt;
  &lt;li&gt;The tokens have variable lengths. In order to fix this, we have to padd all
sequences during learning. Because we padd, we have to mask the padding
during training for both VAE and upper LM. Keeping track of this is pretty
nifty and it means gradients on rarely used places will rarely get updated. So
we will almost surely miss some letters in our tokens. Either at the front or
the end of the token depending on how we padd the tokens.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;future-work&quot;&gt;&lt;strong&gt;Future work&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Actually testing discretizing the tokens to compare with the regular BPE. In that direction,
also comparing with a randomized tokenizer as used in &lt;a href=&quot;https://github.com/google/sentencepiece&quot;&gt;SentencePiece&lt;/a&gt;
to make sure the results are actually comparable and are indeed linked to tokenization variance.&lt;/li&gt;
  &lt;li&gt;The masking problem really seems to be a current limit of the model. Finding a workaround would be really valuable.&lt;/li&gt;
  &lt;li&gt;The fact that the NLL loss is required slows down upper layers. It would be awesome if we could smooth out
the encoding/decoding matrix so that L2 directly for VAE and the upper layer works. It probably goes against regular
language model embedding so not sure it’s doable.&lt;/li&gt;
  &lt;li&gt;Making the epsilon based tokenization directly after the embedding layer. This would help &lt;em&gt;stack&lt;/em&gt; those levels hopefully learning
higher and higer representations of text leading the sentence embedding and so on.&lt;/li&gt;
  &lt;li&gt;On the same idea, another direction would be to do actual discrete tokenization to allow for the models to stack.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>nicolas</name></author><summary type="html">In the first segment we looked into how we could make a BPE based encoding, not only based on frequency in the dataset, but directly on the model probability measure of the next token. In that article I mention that dynamic BPE are costly because they stop being a one time operation but have to be done for every batch because the vocabulary might have changed. In this article I try to completely remove the “static” BPE approach and replace it completely with ML blocks.</summary></entry><entry><title type="html">Model based encodings</title><link href="https://narsil.github.io/narsil.github.io/ml/nlp/2019/05/16/model-based-bpe-encodings.html" rel="alternate" type="text/html" title="Model based encodings" /><published>2019-05-16T00:00:00-05:00</published><updated>2019-05-16T00:00:00-05:00</updated><id>https://narsil.github.io/narsil.github.io/ml/nlp/2019/05/16/model-based-bpe-encodings</id><content type="html" xml:base="https://narsil.github.io/narsil.github.io/ml/nlp/2019/05/16/model-based-bpe-encodings.html">&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Byte_pair_encoding&quot;&gt;Byte-pair encodings&lt;/a&gt; (BPE) are now very commonly used in NLP. In &lt;a href=&quot;https://openai.com/blog/better-language-models/&quot;&gt;GPT-2&lt;/a&gt;, Byte-pair encodings are used to preformat the raw texts before feeding the model. But this is a relatively costly step for your preprocessing and has some limitations. For instance, you have to split your data on spaces if you want your byte pair algorithm to compute in reasonable time.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h1 id=&quot;tldr-in-this-article-we-present-an-idea-to-generate-byte-pair-encodings-not-based-on-frequency-in-the-dataset-but-on-the-quality-of-the-prediction-of-our-model-this-enables-us-to-predict-multi-word-tokens-like-new-york-and-address-languages-that-dont-use-spaces-to-split-words&quot;&gt;TL;DR In this article we present an idea to generate Byte pair encodings, not based on frequency in the dataset, but on the quality of the prediction of our model. This enables us to predict multi word tokens like “New York” and address languages that don’t use spaces to split words.&lt;/h1&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;what-are-byte-pair-encodings-&quot;&gt;What are Byte Pair Encodings ?&lt;/h2&gt;

&lt;p&gt;Byte-pair encodings are a way to compress information from pairs of bytes that will form tokens. Let’s take an example :&lt;/p&gt;

&lt;p&gt;“I love carrots and I love apples.”&lt;/p&gt;

&lt;p&gt;This sentence read by a computer is only a sequence of bytes (bytes are simply a number between 0 and 255). That means to a computer our sentence looks like&lt;/p&gt;

&lt;p&gt;“I love carrots and I love apples.” -&amp;gt; [73, 32, 108, 111, 118, 101, 32, 99, 97, 114, 114, 111, 116, 115, 32, 97, 110, 100, 32, 73, 32, 108, 111, 118, 101, 32, 97, 112, 112, 108, 101, 115, 46]&lt;/p&gt;

&lt;p&gt;From that example, you may remark that some bytes are occurring multiple times together like [108, 111] that occurs twice (it’s “lo” from “love”). So let’s build a new token for this frequent pair. Numbers from 0 to 255 are already taken so we’ll take the next available number which is 256, and we are going to store that information in a table&lt;/p&gt;

&lt;p&gt;[108, 111] -&amp;gt; 256&lt;/p&gt;

&lt;p&gt;Now if we use that new token to encode our original bytes, whenever we encounter [108, 111], we’ll replace that by 256, so the original byte string becomes :&lt;/p&gt;

&lt;p&gt;[73, 32, 108, &lt;strong&gt;256&lt;/strong&gt;, 101, 32, 99, 97, 114, 114, 111, 116, 115, 32, 97, 110, 100, 32, 73, 32, &lt;strong&gt;256&lt;/strong&gt;, 118, 101, 32, 97, 112, 112, 108, 101, 115, 46]&lt;/p&gt;

&lt;p&gt;We went from 33 numbers to 31 numbers. We can rinse and repeat to compress the number of numbers even further. Originally, BPE was proposed as a compression algorithm. It’s not the best compression tool, so we won’t look at that side of the algorithm. Now you get what we are looking at when we train a model on BPEs, just a list of numbers.&lt;/p&gt;

&lt;p&gt;Typically a BPE vocabulary contains ~10k tokens (GPT-2 has 50k), that means it can capture very frequent words like “the” entirely, and parts of words that contain many variations like “ment” (&lt;strong&gt;ment&lt;/strong&gt;ally, environ&lt;strong&gt;ment&lt;/strong&gt; …). What’s great about it it that you can now have words share semantic parts of them for their representation in your model so (environ-ment, environ-ment-al, environ-ment-ally will all share “environ” which will contain most of the semantic meaning, the rest will contain grammar information hopefully).&lt;/p&gt;

&lt;p&gt;The real advantage of BPE over classical Word Embeddings is that it does not fall into the out-of-vocabulary error (when a word was not seen). At worse you can always fall back to single bytes.&lt;/p&gt;

&lt;h2 id=&quot;whats-the-problem-with-bpe-&quot;&gt;&lt;strong&gt;What’s the problem with BPE ?&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;BPE algorithm is pretty bad in terms of complexity to calculate (roughly O(n²), you can look at a very good implementation &lt;a href=&quot;https://github.com/glample/fastBPE&quot;&gt;https://github.com/glample/fastBPE&lt;/a&gt;). BPE is also pretty bad when you want to encode some new text. A greedy algorithm will be O(n) but not the best encoding possible, the best encoding possible is actually O(n²) in the general case.&lt;/p&gt;

&lt;p&gt;To be honest, most implementations split on spaces as mentioned earlier which speeds up the algorithm quite a bit. Once we have encoded a full word like “the” there is no way to add tokens to it, so it’s not necessary to look at it anymore for potential byte pairs, so we can assume the encoding&amp;amp;table creation go from O(n²) to something much closer to O(n). In addition, at encoding time, once we know the encoding for “the” we can cache that information leading to further speed ups. But using spaces as a special character has drawbacks, namely:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;We can’t address as well languages that don’t use a space to separate words like Chinese (arguably German).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We can’t encode frequently occurring multi words like “New York” or “European Union” or “black holes”&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The second problem is especially bad when you consider examples where semantic is very different from the composing words like “Chicago Bulls” have nothing to do with bulls.&lt;/p&gt;

&lt;h2 id=&quot;ε-bpe-or-model-based-bpe-encoding&quot;&gt;&lt;strong&gt;ε-BPE or model based BPE encoding&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;The core idea is that instead of using frequency in the dataset to create the byte pairs, we can use the probability transition of the model to create the BPE. Let’s use some kind of transformer, GPT-2 for instance. The core idea of that model, is to predict the next token (in the BPE sense) given a fixed context size. But we can use the output probability of the model in order to create new tokens, not because they are frequent but because they are easy to predict. For instance in a book that contains a character “Sir Francis” that appears rarely, but there is only one character named “Sir …”, the algorithm might learn quite easily that “Sir “ is followed by “Francis” with great confidence, even if the occurence of the words is pretty low compared to common words like “the”, “like” and “I”.&lt;/p&gt;

&lt;p&gt;So the core algorithm, will train a simple transformer on a dataset on regular bytes (at least at the start). Then, as the algorithm learns, some predictions will be above 1-ε. We can keep track of those and keep track of the last token we received, to check if we were correct.&lt;/p&gt;

&lt;p&gt;Let’s keep a hit map to see how successful our algorithm is. For instance, I predicted “Fo” will be followed by “gg” (Phileas Fogg is a character in Around the world in 80 days) with probability &amp;gt; 1-ε. I was correct in 14 cases, and got it wrong in 1 case (let’s say it was classical “Fo” “g “). We were correct 14/15 times that’s 93% accuracy. If we look at the fluctuation interval associated with that, we get [92.74-93.25%] range. If 92.74 &amp;gt; 1–ε we can conclude that our transition prediction is really very good, it’s not a fluke of the model.&lt;/p&gt;

&lt;p&gt;More generally, if we want 95% confidence when we upgrade this transition, we need to respect the following inequality : k / n - 1/sqrt(n) &amp;gt; 1-ε, where k is the number of successful predictions, n is the total number of predictions and ε the probability margin explained earlier.&lt;/p&gt;

&lt;p&gt;This model is slightly different from byte pair encoding, but now we don’t suffer from the 2 problems mentioned above, we can get pretty long tokens if the dataset allows for it, and we can use Chinese or German as the space character does not play any special role.&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Implementation can be found here. On the first run, we ran on a book &lt;a href=&quot;https://en.wikipedia.org/wiki/Around_the_World_in_Eighty_Days&quot;&gt;Around the world in 80 days&lt;/a&gt; by Jules Verne. It’s a very small dataset but the idea is to check that we can actually overcome BPE’s limitations. Here are a few telling tokens that were created while running on the dataset :&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Promotion #&lt;/th&gt;
      &lt;th&gt;Token created&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;338&lt;/td&gt;
      &lt;td&gt;“Mr. Fogg”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;357&lt;/td&gt;
      &lt;td&gt;“Phileas Fogg”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;360&lt;/td&gt;
      &lt;td&gt;“Passepartout”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;635&lt;/td&gt;
      &lt;td&gt;“ir Franc” (Sir Francis)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;781&lt;/td&gt;
      &lt;td&gt;“It was”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;900&lt;/td&gt;
      &lt;td&gt;’” asked’ (contains a quote character)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;What is interesting, it that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;We managed to create multi word tokens like “Phileas Fogg”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multi word tokens are a minority in terms of tokens created by the algorithm. Out of 421 tokens that contain a space character only 27 are multi word tokens like “New York”. The remaining 394 tokens contain an ending space, meaning our algorithm is learning word boundaries. It is reassuring because traditional BPE are usually hardcoding that information.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multi word tokens are name of characters in the book, which are occurring frequently, they are an entity by themselves (Fogg even has 2 tokens associated to him)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;2 Multi word tokens are &lt;strong&gt;not&lt;/strong&gt; specific to the book, “it was” is a pretty common 2 word token in English in descriptions, “(…) asked” is a very common continuation when we start a quote and end a sentence with a question mark. We can guess that “(…) said” would be a token further down the line, but it’s harder as there are probably a wider variety of verbs that can fit (said, replied, answered and so on…)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here is a more complete comparison of standard BPE with ε-BPE, with the first 100 tokens generated, as you can see more tokens are dedicated to syntax in eBPE, which Standard BPE ignore gladly by splitting on newlines and spaces.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Standard BPE&lt;/th&gt;
      &lt;th&gt;eBPE&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;‘th’&lt;/td&gt;
      &lt;td&gt;‘\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘the ‘&lt;/td&gt;
      &lt;td&gt;’, ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘an’&lt;/td&gt;
      &lt;td&gt;‘d ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘in’&lt;/td&gt;
      &lt;td&gt;‘Th’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ou’&lt;/td&gt;
      &lt;td&gt;‘ve’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘er’&lt;/td&gt;
      &lt;td&gt;‘y ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ed ‘&lt;/td&gt;
      &lt;td&gt;’; ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ar’&lt;/td&gt;
      &lt;td&gt;‘f ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘hi’&lt;/td&gt;
      &lt;td&gt;’,\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘on’&lt;/td&gt;
      &lt;td&gt;‘\r\n\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘re’&lt;/td&gt;
      &lt;td&gt;‘th’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘en’&lt;/td&gt;
      &lt;td&gt;‘qu’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘and ‘&lt;/td&gt;
      &lt;td&gt;‘the’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘of ‘&lt;/td&gt;
      &lt;td&gt;’ ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘st’&lt;/td&gt;
      &lt;td&gt;‘the ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘to ‘&lt;/td&gt;
      &lt;td&gt;‘The’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘as ‘&lt;/td&gt;
      &lt;td&gt;‘\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘se’&lt;/td&gt;
      &lt;td&gt;’, ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ha’&lt;/td&gt;
      &lt;td&gt;‘y ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘or’&lt;/td&gt;
      &lt;td&gt;‘d ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;’.\r ‘&lt;/td&gt;
      &lt;td&gt;‘Th’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘it’&lt;/td&gt;
      &lt;td&gt;‘ve’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘he ‘&lt;/td&gt;
      &lt;td&gt;’; ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘le’&lt;/td&gt;
      &lt;td&gt;‘f ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ing ‘&lt;/td&gt;
      &lt;td&gt;’,\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;’,\r ‘&lt;/td&gt;
      &lt;td&gt;’ ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘as’&lt;/td&gt;
      &lt;td&gt;‘\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘in ‘&lt;/td&gt;
      &lt;td&gt;’, ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘at’&lt;/td&gt;
      &lt;td&gt;‘d ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘at ‘&lt;/td&gt;
      &lt;td&gt;‘y ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ro’&lt;/td&gt;
      &lt;td&gt;‘Th’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘er ‘&lt;/td&gt;
      &lt;td&gt;‘ve’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘al’&lt;/td&gt;
      &lt;td&gt;‘f ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘es’&lt;/td&gt;
      &lt;td&gt;’; ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘on ‘&lt;/td&gt;
      &lt;td&gt;’ ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘was ‘&lt;/td&gt;
      &lt;td&gt;’,\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘no’&lt;/td&gt;
      &lt;td&gt;‘th’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘his ‘&lt;/td&gt;
      &lt;td&gt;‘\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ed’&lt;/td&gt;
      &lt;td&gt;’, ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ac’&lt;/td&gt;
      &lt;td&gt;‘d ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;’“\r ‘&lt;/td&gt;
      &lt;td&gt;‘y ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ri’&lt;/td&gt;
      &lt;td&gt;‘Th’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘be’&lt;/td&gt;
      &lt;td&gt;‘ve’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ly ‘&lt;/td&gt;
      &lt;td&gt;‘f ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘om’&lt;/td&gt;
      &lt;td&gt;’; ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘li’&lt;/td&gt;
      &lt;td&gt;’ ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘en ‘&lt;/td&gt;
      &lt;td&gt;’,\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ti’&lt;/td&gt;
      &lt;td&gt;‘th’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘og’&lt;/td&gt;
      &lt;td&gt;‘\r\n\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ra’&lt;/td&gt;
      &lt;td&gt;‘the’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘di’&lt;/td&gt;
      &lt;td&gt;‘the ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘art’&lt;/td&gt;
      &lt;td&gt;‘The’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘Fog’&lt;/td&gt;
      &lt;td&gt;‘qu’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘the’&lt;/td&gt;
      &lt;td&gt;’s ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ma’&lt;/td&gt;
      &lt;td&gt;‘The ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ve ‘&lt;/td&gt;
      &lt;td&gt;‘g ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘is ‘&lt;/td&gt;
      &lt;td&gt;’,”’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘or ‘&lt;/td&gt;
      &lt;td&gt;‘no’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ld ‘&lt;/td&gt;
      &lt;td&gt;‘t ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘whi’&lt;/td&gt;
      &lt;td&gt;‘th ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘il’&lt;/td&gt;
      &lt;td&gt;‘o ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ur’&lt;/td&gt;
      &lt;td&gt;’?”’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;’s, ‘&lt;/td&gt;
      &lt;td&gt;‘\r\n\r\n”’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘de’&lt;/td&gt;
      &lt;td&gt;’,” ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘wh’&lt;/td&gt;
      &lt;td&gt;‘Mr’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘lo’&lt;/td&gt;
      &lt;td&gt;‘e ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ch ‘&lt;/td&gt;
      &lt;td&gt;‘yo’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ere ‘&lt;/td&gt;
      &lt;td&gt;‘Yo’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ith ‘&lt;/td&gt;
      &lt;td&gt;‘ou’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘The ‘&lt;/td&gt;
      &lt;td&gt;’. ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘am’&lt;/td&gt;
      &lt;td&gt;‘nd ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ent’&lt;/td&gt;
      &lt;td&gt;‘h ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘un’&lt;/td&gt;
      &lt;td&gt;‘n ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘gh’&lt;/td&gt;
      &lt;td&gt;’;\r\n’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘with ‘&lt;/td&gt;
      &lt;td&gt;‘og’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘an ‘&lt;/td&gt;
      &lt;td&gt;‘you’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘oun’&lt;/td&gt;
      &lt;td&gt;‘r ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘part’&lt;/td&gt;
      &lt;td&gt;‘of ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ver’&lt;/td&gt;
      &lt;td&gt;‘to ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘si’&lt;/td&gt;
      &lt;td&gt;’s F’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘had ‘&lt;/td&gt;
      &lt;td&gt;‘Pa’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘not ‘&lt;/td&gt;
      &lt;td&gt;‘as ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ould ‘&lt;/td&gt;
      &lt;td&gt;'’s ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ing’&lt;/td&gt;
      &lt;td&gt;’. F’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘out ‘&lt;/td&gt;
      &lt;td&gt;‘is ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘el’&lt;/td&gt;
      &lt;td&gt;‘ld ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘sa’&lt;/td&gt;
      &lt;td&gt;‘ng ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ce’&lt;/td&gt;
      &lt;td&gt;‘at ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘that ‘&lt;/td&gt;
      &lt;td&gt;‘re’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘asse’&lt;/td&gt;
      &lt;td&gt;‘ve ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘fi’&lt;/td&gt;
      &lt;td&gt;‘gh’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ol’&lt;/td&gt;
      &lt;td&gt;‘ut ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘sh’&lt;/td&gt;
      &lt;td&gt;‘ll’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘r. ‘&lt;/td&gt;
      &lt;td&gt;‘Pas’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;’.”\r ‘&lt;/td&gt;
      &lt;td&gt;‘re ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘Passe’&lt;/td&gt;
      &lt;td&gt;‘ed ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘Passepart’&lt;/td&gt;
      &lt;td&gt;’. Fog’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ut ‘&lt;/td&gt;
      &lt;td&gt;‘ch ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘which ‘&lt;/td&gt;
      &lt;td&gt;‘and ‘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;‘ay’&lt;/td&gt;
      &lt;td&gt;‘ea’&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I would love to check the tokenization of German or Chinese but I’m not a speaker of either language so it’s hard for me to analyze the results anyway. What’s for sure is that the technique is applicable.&lt;/p&gt;

&lt;p&gt;I also tried the technique on different types of files like wav files or mp3 files, even jpeg images. Analysis is harder to do. Still some interesting notes, it took longer for the model to emit new tokens on the mp3 files than on the wav files. The mp3 file is encoded, therefore should have a lower entropy (meaning it’s harder to predict the next token) than the wav files so the model takes longer to actually get good at predicting. It’s probable (I haven’t checked) that we have to overfit the mp3 file and jpeg files before we can predict any meaningful content (except maybe the header part)&lt;/p&gt;

&lt;h2 id=&quot;future-work&quot;&gt;&lt;strong&gt;Future Work&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Many interesting ideas are still left to explore to continue exploring the idea of models creating their own tokenization. For now a limiting factor is the actual BPE encoding process that takes longer and longer as the model creates new tokens. That’s because the encoding process is done in Python, so it’s quite slow and can’t be precalculated as you would do with fixed BPE encodings. To give a sense of the slowdown, the training loop starts at ~11it/s on a GTX970 and finished at roughly 10s/it. That’s a 100x slowdown over the course of the training, with only 1k tokens in the end, far from the 50k used by GPT-2 for instance.&lt;/p&gt;

&lt;p&gt;It’s going to be an actual requirement to train on larger and more representative datasets. Training on bigger datasets would help us understand how important are those multi word tokens and maybe what are those multi words. The token “(…) &lt;strong&gt;asked&lt;/strong&gt;” was pretty surprising to me, I’m eager to see what else can be discovered.&lt;/p&gt;

&lt;p&gt;The actual epsilon used was 40% which actually quite a big (value was chosen with trial and error, to get a small but not null rejection rate of new tokens, to add tokens as fast as possible but not making too many mistakes). That value probably has a sweet spot depending on the number of current tokens, after speeding up the process it would be interesting to look at the best value for epsilon as a function of the number of tokens.&lt;/p&gt;</content><author><name>nicolas</name></author><summary type="html">Byte-pair encodings (BPE) are now very commonly used in NLP. In GPT-2, Byte-pair encodings are used to preformat the raw texts before feeding the model. But this is a relatively costly step for your preprocessing and has some limitations. For instance, you have to split your data on spaces if you want your byte pair algorithm to compute in reasonable time.</summary></entry></feed>