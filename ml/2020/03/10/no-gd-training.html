<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><link rel="shortcut icon" type="image/x-icon" href="/narsil.github.io/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Can we train neural networks without gradient descent ? | Narsil</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Can we train neural networks without gradient descent ?" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="If the lottery ticket hypothesis is real, does that mean we can train a neural network without gradient descent?" />
<meta property="og:description" content="If the lottery ticket hypothesis is real, does that mean we can train a neural network without gradient descent?" />
<link rel="canonical" href="https://narsil.github.io/narsil.github.io/ml/2020/03/10/no-gd-training.html" />
<meta property="og:url" content="https://narsil.github.io/narsil.github.io/ml/2020/03/10/no-gd-training.html" />
<meta property="og:site_name" content="Narsil" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-10T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"If the lottery ticket hypothesis is real, does that mean we can train a neural network without gradient descent?","@type":"BlogPosting","headline":"Can we train neural networks without gradient descent ?","dateModified":"2020-03-10T00:00:00-05:00","url":"https://narsil.github.io/narsil.github.io/ml/2020/03/10/no-gd-training.html","datePublished":"2020-03-10T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://narsil.github.io/narsil.github.io/ml/2020/03/10/no-gd-training.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
  <link rel="stylesheet" href="/narsil.github.io/assets/main.css">
  <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://narsil.github.io/narsil.github.io/feed.xml" title="Narsil" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
          ]}
        );
      });
    </script>
  

  <script>
  function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
  }
  window.onload = wrap_img;
  </script>

  <script>
    document.addEventListener("DOMContentLoaded", function(){
      // add link icon to anchor tags
      var elem = document.querySelectorAll(".anchor-link")
      elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
      // remove paragraph tags in rendered toc (happens from notebooks)
      var toctags = document.querySelectorAll(".toc-entry")
      toctags.forEach(e => (e.firstElementChild.innerText = e.firstElementChild.innerText.replace('¶', '')))
    });
  </script>
</head><body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/narsil.github.io/">Narsil</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/narsil.github.io/about/">About Me</a><a class="page-link" href="/narsil.github.io/search/">Search</a><a class="page-link" href="/narsil.github.io/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Can we train neural networks without gradient descent ?</h1><p class="page-description">If the lottery ticket hypothesis is real, does that mean we can train a neural network without gradient descent?</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-03-10T00:00:00-05:00" itemprop="datePublished">
        Mar 10, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      18 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/narsil.github.io/categories/#ml">ml</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">
<a href="https://github.com/Narsil/narsil.github.io/tree/master/_notebooks/2020-03-10-no-gd-training.ipynb" role="button">
    <img class="notebook-badge-image" src="https://img.shields.io/static/v1?label=&message=View%20On%20GitHub&color=586069&logo=github&labelColor=2f363d">
</a>
</div><div class="px-2">
    <a href="https://colab.research.google.com/github/Narsil/narsil.github.io/blob/master/_notebooks/2020-03-10-no-gd-training.ipynb">
        <img class="notebook-badge-image" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#What's-the-problem-?">What&#39;s the problem ? </a></li>
<li class="toc-entry toc-h2"><a href="#Other-approaches">Other approaches </a></li>
<li class="toc-entry toc-h2"><a href="#Our-approach">Our approach </a></li>
<li class="toc-entry toc-h2"><a href="#Experiments">Experiments </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Experiment-1">Experiment 1 </a></li>
<li class="toc-entry toc-h3"><a href="#Experiment-2">Experiment 2 </a></li>
<li class="toc-entry toc-h3"><a href="#Experiment-2-bis">Experiment 2 bis </a></li>
<li class="toc-entry toc-h3"><a href="#Experiment-3">Experiment 3 </a></li>
<li class="toc-entry toc-h3"><a href="#Experiment-4">Experiment 4 </a></li>
<li class="toc-entry toc-h3"><a href="#Experiment-5">Experiment 5 </a></li>
<li class="toc-entry toc-h3"><a href="#Experiment-6--(Unsupervised-text-classification)-or-fuse-with-experiment-4?">Experiment 6  (Unsupervised text classification) or fuse with experiment 4? </a></li>
<li class="toc-entry toc-h3"><a href="#Experiment-7">Experiment 7 </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Limits">Limits </a></li>
<li class="toc-entry toc-h2"><a href="#Future-Work">Future Work </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-10-no-gd-training.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What's-the-problem-?">
<a class="anchor" href="#What's-the-problem-?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What's the problem ?<a class="anchor-link" href="#What's-the-problem-?"> </a>
</h2>
<p>ML models usually are not really capable of predicting how well the data you<br>
feed them is close to what was in the dataset. It really matters in production 
models as they might make really stupid mistakes just because they are off<br>
the training set.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's train a simple mnist model (straight out from pytorch tutorial <a href="https://github.com/pytorch/examples/tree/master/mnist">https://github.com/pytorch/examples/tree/master/mnist</a>)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">StepLR</span>
<span class="kn">import</span> <span class="nn">os</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9216</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Train Epoch: </span><span class="si">{}</span><span class="s1"> [</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.0f}</span><span class="s1">%)]</span><span class="se">\t</span><span class="s1">Loss: </span><span class="si">{:.6f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
                <span class="mf">100.</span> <span class="o">*</span> <span class="n">batch_idx</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>


<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'sum'</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># sum up batch loss</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># get the index of the max log-probability</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Test set: Average loss: </span><span class="si">{:.4f}</span><span class="s1">, Accuracy: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.0f}</span><span class="s1">%)</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">mnist</span><span class="p">():</span>
    <span class="c1"># Training settings</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">'PyTorch MNIST Example'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batch-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'input batch size for training (default: 64)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--test-batch-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'input batch size for testing (default: 1000)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--epochs'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'number of epochs to train (default: 14)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--lr'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'LR'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'learning rate (default: 1.0)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--gamma'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'M'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Learning rate step gamma (default: 0.7)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--no-cuda'</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">'store_true'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'disables CUDA training'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--seed'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'S'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'random seed (default: 1)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--log-interval'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'how many batches to wait before logging training status'</span><span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--save-model'</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">'store_true'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'For Saving the current Model'</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="n">use_cuda</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">no_cuda</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'num_workers'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'pin_memory'</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                       <span class="p">])),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">),</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                       <span class="p">])),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">test_batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>

    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">train</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="n">test</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">"mnist_cnn.pt"</span><span class="p">)</span>
        
<span class="c1"># mnist()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Other-approaches">
<a class="anchor" href="#Other-approaches" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other approaches<a class="anchor-link" href="#Other-approaches"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Other out of distribution detector have been proposed. Here is a sample of methods:</p>
<ul>
<li>
<a href="https://arxiv.org/pdf/1906.02845.pdf">Likelihood Ratios for Out-of-Distribution Detection</a>: Propose to learn 2 distinct models, one "raw", one with perturbation instilled into the dataset, and look at the log likelihood ratio of the two models, claim is that the difference between the two will reflect how "far" input is from the semantic part of the manifold of X. $p(x) = p(x_{background})p(x_{semantic})$, the perturbation needs to lie only on $x_{semantic}$.</li>
<li>
<a href="https://arxiv.org/pdf/1910.04241.pdf">Out-of-distribution Detection in Classifiers via Generation</a>: Propose to use autoencoder (or GANs) to generate a low dimensional representation of the manifold of the dataset X, then perturb X on that representation. Those perturbated examples are trained to become a new "class" of the output of the classifier. </li>
<li>
<a href="https://arxiv.org/pdf/1706.02690.pdf">Enhancing the reliability of Out-of-Distribution Image Detection in Neural Networks (Odin)</a>: This one uses temperature scaling regarding softmax to generate perturbated input, then look at the probability of the softmax if it passes a threshold. IMO, this paper is interesting as it supposes smoothness properties on In distribution data, and less smooth for out-of-distribution. It does require some examples of out-of-distribution for fitting 3 hyperparameters (temperature, threshold and magnitude of perturbation)</li>
<li>
<p><a href="https://openreview.net/pdf?id=Hkxzx0NtDB">Your classifier is secretly an energy based model and you should treat it like one</a>: This one adds a new term in the loss to estimate p(x) basically. Multiple ood detectors are proposed, the most efficient being the second derivative of p(x), claiming again that density of p(x) will change more widly in ood space, leading to a good ood detector.</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1810.01392.pdf">WAIC, but Why? Generative Ensembles for Robust Anomaly Detection</a>: This paper proposes to use an ensemble of models and look at WAIC criterion to detect OOD. It makes many comparison to VAE and GANs</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1802.04865v1.pdf">Learning Confidence for Out-of-Distribution Detection in Neural Networks</a> : The core idea in this paper is to change the learning loss, to learn confidence as prior task to classification task, a model is allowed to see real label only when it claims it can solve the problem, outputting via another head directly a confidence score. Caveat is that the model might choose to give up and always claim confidence, and another trick is proposed to emphasize the in-distribution vs out-of-distribution by preprocessing inputs to move them towards region of higher confidence. In-distribution tends to move closer to 1 than out-of-distribution. So the direct confidence estimator seems to be <em>smoother</em> out-of-distribution than in-distribution, where peaks are more likely to be found.</p>
</li>
<li>
<p><a href="https://paperswithcode.com/task/out-of-distribution-detection">Papers with code</a>: More links on that hopefully</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Our-approach">
<a class="anchor" href="#Our-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Our approach<a class="anchor-link" href="#Our-approach"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p><strong>Tl;dr : Make two similar models, with two different random initialization, then train them at the same time.&gt; The ood detector will simply be the a threshold classifier on the KL-divergence between the two outputs.</strong>
The core argument for this approach is that the neural network captures the dataset manifold (which means it will produce "regular" outputs for in dataset items). For the range of possible values it has random values for a random initialization. If that is true, then we train the model, we shift it's output only on the dataset manifold, and not anywhere else. If that assumption is correct, then the 2 models have very low probability of concurring in their output outside of the manifold if they have been initialized differently.</p>
</blockquote>
<p>It's quite close to WAIC, <em>but</em> the two models need to be trained at the same time. The argument is that is should align gradients during the training phase, leading to more correlation for in-dataset prediction for the models. The argument for this supposes that the lottery ticket hypothesis is true, and adds that lottery ticket is unique (or at least that the class of lottery tickets is very thin, and they all highly correlate to each other). If this is true, then the gradients within the network that correspond to this lottery ticket winner in <em>both</em> networks should be the same (or highly correlated).</p>
<p>In order to fix the threshold, we found that simply setting it to be 10x the average kl-divergence obtained on the train dataset worked pretty well. As kl divergence is measured in bits, 10x is a quite large margin. More work could be done to study more closely the behaviour of this self kl-divergence.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Experiments">
<a class="anchor" href="#Experiments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiments<a class="anchor-link" href="#Experiments"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Experiment-1">
<a class="anchor" href="#Experiment-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiment 1<a class="anchor-link" href="#Experiment-1"> </a>
</h3>
<p>MNIST attack like failure presented before.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MultiNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">models</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">]</span>

    
<span class="k">def</span> <span class="nf">train_multi</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Train Epoch: </span><span class="si">{}</span><span class="s1"> [</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.0f}</span><span class="s1">%)]</span><span class="se">\t</span><span class="s1">Loss: </span><span class="si">{:.6f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
                <span class="mf">100.</span> <span class="o">*</span> <span class="n">batch_idx</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>


<span class="k">def</span> <span class="nf">test_multi</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'sum'</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># get the index of the max log-probability</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Test set: Average loss: </span><span class="si">{:.4f}</span><span class="s1">, Accuracy: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.0f}</span><span class="s1">%)</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">mnist_multi</span><span class="p">():</span>
    <span class="c1"># Training settings</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">'PyTorch MNIST Example'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batch-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'input batch size for training (default: 64)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--test-batch-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'input batch size for testing (default: 1000)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--epochs'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'number of epochs to train (default: 14)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--lr'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'LR'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'learning rate (default: 1.0)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--gamma'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'M'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Learning rate step gamma (default: 0.7)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--no-cuda'</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">'store_true'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'disables CUDA training'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--seed'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'S'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'random seed (default: 1)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--log-interval'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'how many batches to wait before logging training status'</span><span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--save-model'</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">'store_true'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'For Saving the current Model'</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="n">use_cuda</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">no_cuda</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'num_workers'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'pin_memory'</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                       <span class="p">])),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">),</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                       <span class="p">])),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">test_batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">model1</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">model2</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">MultiNet</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>

    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">train_multi</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="n">test_multi</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">"mnist_multi_cnn.pt"</span><span class="p">)</span>
        

<span class="c1"># mnist_multi()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="k">def</span> <span class="nf">kl</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'sum'</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'sum'</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>


    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Test set: Average loss: </span><span class="si">{:.4f}</span><span class="s1">, len </span><span class="si">{}</span><span class="s1"> </span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">test_loss</span>
    
<span class="n">multi_model</span> <span class="o">=</span> <span class="n">MultiNet</span><span class="p">(</span><span class="n">Net</span><span class="p">(),</span> <span class="n">Net</span><span class="p">())</span>
<span class="n">multi_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'mnist_multi_cnn.pt'</span><span class="p">))</span>


<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">),</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                       <span class="p">])),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ref_kl_loss</span> <span class="o">=</span> <span class="n">kl</span><span class="p">(</span><span class="n">multi_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">,</span> <span class="n">test_loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Test set: Average loss: 0.0069, len 10000 

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we have 2 models capable of detecting digits, we have instantly 3 checks for checking if the output of our model is valid. The 2 models need to be concording (they need to outputs the same digit as an output), they need to have similar kl-divergence, we actually have a reference for the test set, so we know what kind of divergence we should look for, anything 10x more is definitely ood (we could look at the test set distribution for more fine grain estimation). Because kl divergence is asymetric we have 2 values (it's harder for spiked distribution to have another distribution be close in the kl sense, so taking the max of kl-divergence should be used for out-of-distribution.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Categorical</span>
<span class="kn">from</span> <span class="nn">torch.nn.parameter</span> <span class="kn">import</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="k">def</span> <span class="nf">attack</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">multi_model</span> <span class="o">=</span> <span class="n">MultiNet</span><span class="p">(</span><span class="n">Net</span><span class="p">(),</span> <span class="n">Net</span><span class="p">())</span>
    <span class="n">multi_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'mnist_multi_cnn.pt'</span><span class="p">))</span>

    <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">([</span><span class="n">dummy_input</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">multi_model</span><span class="p">(</span><span class="n">dummy_input</span><span class="p">)</span>
        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="c1"># print(f'Entropy {entropy.item():.2f}')</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">MAX1</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">MAX2</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">kl_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'batchmean'</span><span class="p">)</span>
    <span class="n">kl_loss2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'batchmean'</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">kl_loss</span> <span class="o">/</span> <span class="n">ref_kl_loss</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">10</span> <span class="ow">or</span> <span class="n">kl_loss2</span> <span class="o">/</span> <span class="n">ref_kl_loss</span> <span class="o">&gt;</span> <span class="mi">10</span> <span class="ow">or</span> <span class="n">MAX1</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">!=</span> <span class="n">MAX2</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">item</span><span class="p">():</span>
        <span class="n">success</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">success</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"MNIST Model says : This is a </span><span class="si">{</span><span class="n">MAX1</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2"> with probability </span><span class="si">{</span><span class="n">MAX1</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"MNIST Model 2 says : This is a </span><span class="si">{</span><span class="n">MAX2</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2"> with probability </span><span class="si">{</span><span class="n">MAX2</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"KL-divergence is </span><span class="si">{</span><span class="n">kl_loss</span> <span class="o">/</span> <span class="n">ref_kl_loss</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">kl_loss2</span> <span class="o">/</span> <span class="n">ref_kl_loss</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">success</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"ATTACK SUCCEEDED"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"ATTACK FAILED"</span><span class="p">)</span>
        <span class="n">pil_img</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">240</span><span class="p">,</span> <span class="mi">240</span><span class="p">))(</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">()(</span><span class="n">dummy_input</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">display</span><span class="p">(</span><span class="n">pil_img</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">success</span>
        
        
  
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now if we simply attack the first model like we did earlier, we can see that we can trick it as easily as before. <em>BUT</em> the second model, does not get attacked which is to be expected.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
    <span class="n">entropy</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
    
    <span class="n">loss</span> <span class="o">=</span> <span class="n">entropy</span>
    <span class="k">return</span> <span class="n">loss</span>

<span class="n">attack</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>MNIST Model says : This is a 5 with probability 99.32%
MNIST Model 2 says : This is a 1 with probability 51.35%
KL-divergence is 879.1231689453125 221.9772186279297
ATTACK FAILED
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>False</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Even if we try a smarter and attack <strong>both</strong> models at the same time, we can't succeed at a consistent rate. Be warned, it will succeed sometimes, just not consistently.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
    <span class="n">entropy1</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
    <span class="n">entropy2</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>

    <span class="n">kl_loss1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'batchmean'</span><span class="p">)</span>
    <span class="n">kl_loss2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'batchmean'</span><span class="p">)</span>

    <span class="n">distance</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">entropy1</span> <span class="o">+</span> <span class="n">entropy2</span>  <span class="o">+</span> <span class="n">kl_loss1</span> <span class="o">+</span> <span class="n">kl_loss2</span> <span class="o">+</span> <span class="n">distance</span>
    <span class="k">return</span> <span class="n">loss</span>
    
<span class="n">_</span> <span class="o">=</span> <span class="n">attack</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>MNIST Model says : This is a 7 with probability 11.34%
MNIST Model 2 says : This is a 1 with probability 11.91%
KL-divergence is 0.8557947278022766 0.8770337104797363
ATTACK FAILED
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>False</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Be warned, it will succeed sometimes, just not consistently. For comparison, the first attack succeeds with close to 100% (we couldn't make it fail). Actually because we have 10 classes, and if we supposed out-of-distribution probability distribution is uniformly random, it should be something close to 10%, when our initial random image finds a place where the 2 models intersect on the same digit.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
    <span class="n">entropy1</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
    <span class="n">entropy2</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>

    <span class="n">kl_loss1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'batchmean'</span><span class="p">)</span>
    <span class="n">kl_loss2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'batchmean'</span><span class="p">)</span>

    <span class="n">distance</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">entropy1</span> <span class="o">+</span> <span class="n">entropy2</span>  <span class="o">+</span> <span class="n">kl_loss1</span> <span class="o">+</span> <span class="n">kl_loss2</span> <span class="o">+</span> <span class="n">distance</span>
    <span class="k">return</span> <span class="n">loss</span>
    
<span class="n">attacks</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">success</span> <span class="o">=</span> <span class="n">attack</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">success</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"F"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"."</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>
    <span class="n">attacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">success</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">''</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Attack success rate </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">attacks</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">attacks</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
    
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>.........FF.F...F.FF.F..F....FF...F..FF..F.F.F.FF....F....F.......FF......FF.F.FFF.FF..F............Attack success rate 31.00%
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The actual attack range seems to stagnate at around 30% (max observed 41%) with various learning rates and attack steps. There probably are better strategies to attack, this, but the main point is that it became <strong>harder</strong>. This is expected to be a property of the <em>output landscape</em>, as the number of classes increases, it should become harder still. Yet as the 30% is larger than the expected 10%, something else might be at play.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Experiment-2">
<a class="anchor" href="#Experiment-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiment 2<a class="anchor-link" href="#Experiment-2"> </a>
</h3>
<p>Now let's test this on common ood detection for classic datasets. We will add ood detection for the train dataset, just to check that we don't <em>exclude</em> too much of the original dataset. Datasets used will be MNIST, FashionMNIST</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span><span class="p">,</span> <span class="n">Omniglot</span><span class="p">,</span> <span class="n">FashionMNIST</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="n">MNIST</span><span class="p">,</span> <span class="n">FashionMNIST</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">dataset_multi</span><span class="p">(</span><span class="n">dataset_cls</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="c1"># Training settings</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">'PyTorch MNIST Example'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--batch-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'input batch size for training (default: 64)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--test-batch-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'input batch size for testing (default: 1000)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--epochs'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'number of epochs to train (default: 14)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--lr'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'LR'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'learning rate (default: 1.0)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--gamma'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'M'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'Learning rate step gamma (default: 0.7)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--no-cuda'</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">'store_true'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'disables CUDA training'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--seed'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'S'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'random seed (default: 1)'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--log-interval'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">'N'</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'how many batches to wait before logging training status'</span><span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'--save-model'</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">'store_true'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">'For Saving the current Model'</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="n">use_cuda</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">no_cuda</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'num_workers'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'pin_memory'</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset_cls</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                       <span class="p">])),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
                <span class="n">dataset_cls</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                                   <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                   <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                                    <span class="p">])),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">test_batch_size</span><span class="p">)</span>

    <span class="n">model1</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">model2</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">MultiNet</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CyclicLR</span><span class="p">(</span>                             
          <span class="n">optimizer</span><span class="p">,</span> <span class="n">base_lr</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">cycle_momentum</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">step_size_up</span><span class="o">=</span><span class="mi">200</span>                    <span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">train_multi</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="n">test_multi</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">filename</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">run_datasets</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">dataset_cls</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">dataset_cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">.pt'</span>

        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
            <span class="k">continue</span>

        <span class="n">dataset_multi</span><span class="p">(</span><span class="n">dataset_cls</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

<span class="c1"># run_datasets()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_datasets</span><span class="p">():</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span>
    
    <span class="k">for</span> <span class="n">dataset_cls</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">dataset_cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">.pt'</span>
        
        <span class="n">model</span> <span class="o">=</span> <span class="n">MultiNet</span><span class="p">(</span><span class="n">Net</span><span class="p">(),</span> <span class="n">Net</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">))</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
                <span class="n">dataset_cls</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                                   <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                   <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
             <span class="p">])),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">ref_kl_loss</span> <span class="o">=</span> <span class="n">kl</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Ref loss"</span><span class="p">,</span> <span class="n">ref_kl_loss</span><span class="p">)</span>
        
        <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dataset_cls2</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">:</span>
            <span class="n">test_loader2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
                <span class="n">dataset_cls2</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                                   <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                   <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
             <span class="p">])),</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            
            
            <span class="n">OOD</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader2</span><span class="p">:</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
                <span class="n">kl_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'none'</span><span class="p">),</span>  <span class="n">F</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'none'</span><span class="p">))</span>
                <span class="n">kl_loss</span> <span class="o">=</span> <span class="n">kl_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="n">similar</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="n">normed</span> <span class="o">=</span> <span class="n">kl_loss</span> <span class="o">/</span> <span class="n">ref_kl_loss</span>
                
                <span class="n">kl_anomaly</span> <span class="o">=</span> <span class="n">normed</span> <span class="o">&gt;</span> <span class="mi">10</span>
                <span class="n">non_concordant</span> <span class="o">=</span> <span class="n">similar</span> <span class="o">==</span> <span class="kc">False</span>
                
                <span class="n">out_of_distrib</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">kl_anomaly</span> <span class="o">|</span> <span class="n">non_concordant</span><span class="p">)</span>
                
                <span class="n">N</span> <span class="o">=</span> <span class="n">normed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">boolean</span> <span class="o">=</span> <span class="n">dataset_cls2</span> <span class="o">!=</span> <span class="n">dataset_cls</span>
                <span class="n">all_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">boolean</span><span class="p">]</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span>
                <span class="n">all_scores</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">normed</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                
                
                <span class="n">OOD</span> <span class="o">+=</span> <span class="n">out_of_distrib</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Trained on </span><span class="si">{</span><span class="n">dataset_cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> we detected on </span><span class="si">{</span><span class="n">dataset_cls2</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">OOD</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_loader2</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">OOD</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">test_loader2</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%) out of distribution"</span><span class="p">)</span>
                   
        <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">all_labels</span><span class="p">,</span> <span class="n">all_scores</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"AUC for </span><span class="si">{</span><span class="n">dataset_cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> : </span><span class="si">{</span><span class="n">auc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">test_datasets</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Test set: Average loss: 0.0204, len 10000 

Ref loss 0.0204180196672678
Trained on MNIST we detected on MNIST 350/10000 (3.50%) out of distribution
Trained on MNIST we detected on FashionMNIST 7334/10000 (73.34%) out of distribution
AUC for MNIST : 0.9692911949999999

Test set: Average loss: 0.0490, len 10000 

Ref loss 0.0490430459022522
Trained on FashionMNIST we detected on MNIST 6141/10000 (61.41%) out of distribution
Trained on FashionMNIST we detected on FashionMNIST 1040/10000 (10.40%) out of distribution
AUC for FashionMNIST : 0.8571711399999999
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we can see that we achieve, with no tuning whatsoever a decent out of distribution detector. We seem to achieve much better AUROC on MNIST, probably because the in-distribution learning seems to be much better (99% test accuracy vs 92% for fastionMNIST). So to False positives for fashionMNIST probably come from this hard to learn in-distribution. Some fine tuning needs to be done to get better results. We also have to keep in mind, that the models to learn this are quite small (2M parameters but only 2 convolution layers) so the lottery hypothesis validity for such a network might be questionned.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Experiment-2-bis">
<a class="anchor" href="#Experiment-2-bis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiment 2 bis<a class="anchor-link" href="#Experiment-2-bis"> </a>
</h3>
<p>Same experiment but with fine tuned, larger networks on the same datasets</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Experiment-3">
<a class="anchor" href="#Experiment-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiment 3<a class="anchor-link" href="#Experiment-3"> </a>
</h3>
<p>Check that two identical networks (same initalization) actually don't work. It's just a sanity check. We should obtain always kl_div = 0 no matter where we are in the input space.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Experiment-4">
<a class="anchor" href="#Experiment-4" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiment 4<a class="anchor-link" href="#Experiment-4"> </a>
</h3>
<p>Test on a larger output space, like CIFAR-100 and SVHN, to check that part of the limits are actually due to small number of output classes
for MNIST/FashionMNIST
Other idea is to test on Transformers. Early experiment seems to show that we can use that idea to detect different language within text with just the kl_div used as a distance.</p>
<p>Found French book within english books dataset, AND english paragraphs <em>within</em> this french book.
Needs some work to clean this experiment</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Experiment-5">
<a class="anchor" href="#Experiment-5" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiment 5<a class="anchor-link" href="#Experiment-5"> </a>
</h3>
<p>Need to test with various training schemes, regularization schemes (dropout, batchnorm, l2 penalization) and so on. We should find that the smoother in-distribution our models behave the more this method should work. Hopefully test accuracy <em>should</em> be a good smoothness proxy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Experiment-6--(Unsupervised-text-classification)-or-fuse-with-experiment-4?">
<a class="anchor" href="#Experiment-6--(Unsupervised-text-classification)-or-fuse-with-experiment-4?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiment 6  (Unsupervised text classification) or fuse with experiment 4?<a class="anchor-link" href="#Experiment-6--(Unsupervised-text-classification)-or-fuse-with-experiment-4?"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Show that small network trained on a single english book enables to detect different languages
or different patterns of writing (old english, irish, french, or event dictionnaries)</li>
<li>The detection is super fined grained capable of detecting english within a French book.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Experiment-7">
<a class="anchor" href="#Experiment-7" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiment 7<a class="anchor-link" href="#Experiment-7"> </a>
</h3>
<p>Run this method with 2, 3, 4, and so on models. We should get exponential improved accuracy, if the random behavious for out-of-distribution for models is correct.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Limits">
<a class="anchor" href="#Limits" aria-hidden="true"><span class="octicon octicon-link"></span></a>Limits<a class="anchor-link" href="#Limits"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The pros for this method are that:</p>
<ul>
<li>It's super simple to implement, and only costs a constant factor in training time.</li>
<li>You could also extend this to 3, 4 side models, and it <em>should</em> improve robustness exponentially if the random factors are correct. If we keep this number small, it will still be constant cost factor.</li>
<li>It does <em>not</em> require a perturbation model for input data, which in itself is subject to fine-tuning.</li>
</ul>
<p>The cons is that:</p>
<ul>
<li>It does not work so well on low dimensional output spaces. </li>
<li>It seems other methods have better results than this one.</li>
<li>It only works for models that output probability distributions (hard to extend to object detection, generation and other tasks)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Future-Work">
<a class="anchor" href="#Future-Work" aria-hidden="true"><span class="octicon octicon-link"></span></a>Future Work<a class="anchor-link" href="#Future-Work"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There is a lot more experiments necessary to verify that the hypothesis in favor of that approach hold. Try to find ways to implement that in other tasks. How to improve out-of-distribution detection.</p>

</div>
</div>
</div>
</div>


  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="Narsil/narsil.github.io"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/narsil.github.io/ml/2020/03/10/no-gd-training.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/narsil.github.io/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Narsil</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Narsil</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list">
  <li><a href="https://github.com/Narsil"><svg class="social svg-icon"><use xlink:href="/narsil.github.io/assets/minima-social-icons.svg#github"></use></svg> <span class="username">Narsil</span></a></li><li><a href="https://www.twitter.com/narsilou"><svg class="social svg-icon"><use xlink:href="/narsil.github.io/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">narsilou</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Small experiements insights from ML and software development.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
